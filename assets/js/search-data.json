{
  
    
        "post0": {
            "title": "Title",
            "content": "Counting letter using the python language . comments: true | badges: true | . from collections import Counter fname = &quot;Wordle_MysteryWords.csv&quot; def readfile(fname): &#39;&#39;&#39;Reads a file and return the contents as a string&#39;&#39;&#39; f = open(fname, &#39;r&#39;) text = f.read() f.close() return text . def count_letters(words): &#39;&#39;&#39;Returns a dictionary with letters and their counts&#39;&#39;&#39; pass d = {} for word in words: for char in word: if char not in d: d[char] = 1 else: d[char] += 1 return d . def count_words(words): &#39;&#39;&#39;Returns a dictionary with letters and the number of words each letter occurs in&#39;&#39;&#39; d = {} for word in words: chars = set(word) for char in chars: if char not in d: d[char] = 1 else: d[char] += 1 return d . def count_mult(words): &#39;&#39;&#39;Returns a dictionary with the number of times a letter occurs multiple times in a word&#39;&#39;&#39; d = {} for word in words: c = Counter(word) for char in c: if c[char] &gt; 1: if char not in d: d[char] = 1 else: d[char] += 1 return d . def count_pos(words): &#39;&#39;&#39;Returns a dictionary with the number of times each letter occurs in each position in a word&#39;&#39;&#39; d = {} for word in words: for i in range(len(word)): char = word[i] if char not in d: d[char] = [0] * 5 d[char][i] += 1 return d . def count_letters2(words): &#39;&#39;&#39;Use a Counter; functionally the same as count_letters()&#39;&#39;&#39; c = Counter() for word in words: c.update(word) return c . def show_counts(d, title): &#39;&#39;&#39;Print the keys and values from dictionary d&#39;&#39;&#39; print(title) keylist = list(d) keylist.sort() for key in keylist: print(key, d[key]) . def main(): wordstr = readfile(fname) print(wordstr[:30]) wordlist = wordstr.split() print(wordlist[:20]) print(wordlist[-20:]) print(count_letters(wordlist), &quot;Number of times each letter occurs&quot;) print(count_letters2(wordlist), &quot;Number of times each letter occurs&quot;) print(count_words(wordlist), &quot;Number of words each letter occurs in&quot;) print(count_mult(wordlist), &quot;Counts of letters in multiple words&quot;) print(count_pos(wordlist),&quot;Number of times each letter occurs in each position&quot;) main() . abhor abide abled abode abort [&#39;abhor&#39;, &#39;abide&#39;, &#39;abled&#39;, &#39;abode&#39;, &#39;abort&#39;, &#39;about&#39;, &#39;above&#39;, &#39;abuse&#39;, &#39;abyss&#39;, &#39;acorn&#39;, &#39;acrid&#39;, &#39;actor&#39;, &#39;acute&#39;, &#39;adage&#39;, &#39;adapt&#39;, &#39;adept&#39;, &#39;admin&#39;, &#39;admit&#39;, &#39;adobe&#39;, &#39;adopt&#39;] [&#39;wrath&#39;, &#39;wreak&#39;, &#39;wreck&#39;, &#39;wrest&#39;, &#39;wring&#39;, &#39;wrist&#39;, &#39;write&#39;, &#39;wrong&#39;, &#39;wrote&#39;, &#39;wrung&#39;, &#39;wryly&#39;, &#39;yacht&#39;, &#39;yearn&#39;, &#39;yeast&#39;, &#39;yield&#39;, &#39;young&#39;, &#39;youth&#39;, &#39;zebra&#39;, &#39;zesty&#39;, &#39;zonal&#39;] {&#39;a&#39;: 971, &#39;b&#39;: 274, &#39;h&#39;: 389, &#39;o&#39;: 753, &#39;r&#39;: 899, &#39;i&#39;: 671, &#39;d&#39;: 393, &#39;e&#39;: 1230, &#39;l&#39;: 719, &#39;t&#39;: 727, &#39;u&#39;: 467, &#39;v&#39;: 153, &#39;s&#39;: 668, &#39;y&#39;: 424, &#39;c&#39;: 476, &#39;n&#39;: 575, &#39;g&#39;: 311, &#39;p&#39;: 367, &#39;m&#39;: 316, &#39;f&#39;: 230, &#39;x&#39;: 37, &#39;w&#39;: 195, &#39;k&#39;: 209, &#39;z&#39;: 40, &#39;j&#39;: 27, &#39;q&#39;: 29} Number of times each letter occurs Counter({&#39;e&#39;: 1230, &#39;a&#39;: 971, &#39;r&#39;: 899, &#39;o&#39;: 753, &#39;t&#39;: 727, &#39;l&#39;: 719, &#39;i&#39;: 671, &#39;s&#39;: 668, &#39;n&#39;: 575, &#39;c&#39;: 476, &#39;u&#39;: 467, &#39;y&#39;: 424, &#39;d&#39;: 393, &#39;h&#39;: 389, &#39;p&#39;: 367, &#39;m&#39;: 316, &#39;g&#39;: 311, &#39;b&#39;: 274, &#39;f&#39;: 230, &#39;k&#39;: 209, &#39;w&#39;: 195, &#39;v&#39;: 153, &#39;z&#39;: 40, &#39;x&#39;: 37, &#39;q&#39;: 29, &#39;j&#39;: 27}) Number of times each letter occurs {&#39;a&#39;: 904, &#39;o&#39;: 672, &#39;r&#39;: 837, &#39;b&#39;: 262, &#39;h&#39;: 379, &#39;i&#39;: 647, &#39;e&#39;: 1053, &#39;d&#39;: 370, &#39;l&#39;: 648, &#39;t&#39;: 665, &#39;u&#39;: 457, &#39;v&#39;: 149, &#39;s&#39;: 617, &#39;y&#39;: 416, &#39;n&#39;: 550, &#39;c&#39;: 447, &#39;g&#39;: 300, &#39;p&#39;: 346, &#39;m&#39;: 298, &#39;f&#39;: 207, &#39;x&#39;: 37, &#39;w&#39;: 194, &#39;k&#39;: 201, &#39;z&#39;: 35, &#39;j&#39;: 27, &#39;q&#39;: 29} Number of words each letter occurs in {&#39;s&#39;: 49, &#39;a&#39;: 67, &#39;f&#39;: 22, &#39;o&#39;: 81, &#39;g&#39;: 11, &#39;e&#39;: 172, &#39;i&#39;: 24, &#39;l&#39;: 71, &#39;n&#39;: 23, &#39;p&#39;: 19, &#39;r&#39;: 60, &#39;t&#39;: 61, &#39;u&#39;: 10, &#39;b&#39;: 11, &#39;d&#39;: 22, &#39;c&#39;: 29, &#39;m&#39;: 15, &#39;y&#39;: 8, &#39;z&#39;: 5, &#39;h&#39;: 10, &#39;k&#39;: 8, &#39;v&#39;: 4, &#39;w&#39;: 1} Counts of letters in multiple words {&#39;a&#39;: [136, 304, 304, 163, 64], &#39;b&#39;: [173, 11, 55, 24, 11], &#39;h&#39;: [69, 144, 9, 28, 139], &#39;o&#39;: [41, 279, 244, 131, 58], &#39;r&#39;: [105, 267, 163, 152, 212], &#39;i&#39;: [34, 202, 266, 158, 11], &#39;d&#39;: [111, 20, 75, 69, 118], &#39;e&#39;: [72, 242, 177, 317, 422], &#39;l&#39;: [88, 201, 112, 162, 156], &#39;t&#39;: [149, 77, 111, 138, 252], &#39;u&#39;: [33, 186, 165, 82, 1], &#39;v&#39;: [43, 15, 49, 46, 0], &#39;s&#39;: [366, 16, 80, 170, 36], &#39;y&#39;: [6, 23, 29, 3, 363], &#39;c&#39;: [198, 40, 56, 151, 31], &#39;n&#39;: [37, 87, 139, 182, 130], &#39;g&#39;: [115, 12, 67, 76, 41], &#39;p&#39;: [142, 61, 58, 50, 56], &#39;m&#39;: [107, 38, 61, 68, 42], &#39;f&#39;: [136, 8, 25, 35, 26], &#39;x&#39;: [0, 14, 12, 3, 8], &#39;w&#39;: [83, 44, 26, 25, 17], &#39;k&#39;: [20, 10, 12, 55, 112], &#39;z&#39;: [3, 2, 11, 20, 4], &#39;j&#39;: [20, 2, 3, 2, 0], &#39;q&#39;: [23, 5, 1, 0, 0]} Number of times each letter occurs in each position .",
            "url": "https://sakibb019.github.io/Portfolio/2022/09/11/counting-letter.ipynb.html",
            "relUrl": "/2022/09/11/counting-letter.ipynb.html",
            "date": " • Sep 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Covid-19 Analysis using python language.",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt from datetime import datetime . worldometer_df = pd.read_csv(&#39;worldometer_snapshots_April18_to_May18.csv&#39;) worldometer_df = pd.read_csv(&#39;worldometers_snapshots_April18_to_September20.csv&#39;) worldometer_df = pd.read_csv(&#39;worldometers_snapshots_April18_to_August1.csv&#39;) worldometer_df = pd.read_csv(&#39;worldometers_snapshots_April18_to_July30.csv&#39;) worldometer_df = pd.read_csv(&#39;worldometers_snapshots_April18_to_July3.csv&#39;) worldometer_df = pd.read_csv(&#39;worldometers_snapshots_October11_to_October12.csv&#39;) worldometer_df . Date Country Population Total Tests Total Cases Total Deaths Total Recovered Serious or Critical Active Cases . 0 2020-10-11 | USA | 331552784 | 118486898.0 | 7991998 | 219695.0 | 5128162.0 | 14741.0 | 2644141.0 | . 1 2020-10-11 | India | 1383826697 | 86877242.0 | 7119300 | 109184.0 | 6146427.0 | 8944.0 | 863689.0 | . 2 2020-10-11 | Brazil | 212986866 | 17900000.0 | 5094979 | 150506.0 | 4470165.0 | 8318.0 | 474308.0 | . 3 2020-10-11 | Russia | 145952340 | 50781349.0 | 1298718 | 22597.0 | 1020442.0 | 2300.0 | 255679.0 | . 4 2020-10-11 | Colombia | 51035485 | 4173863.0 | 911316 | 27834.0 | 789787.0 | 2220.0 | 93695.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 423 2020-10-12 | Montserrat | 4993 | 483.0 | 13 | 1.0 | 12.0 | NaN | 0.0 | . 424 2020-10-12 | Falkland Islands | 3508 | 2682.0 | 13 | NaN | 13.0 | NaN | 0.0 | . 425 2020-10-12 | Western Sahara | 601379 | NaN | 10 | 1.0 | 8.0 | NaN | 1.0 | . 426 2020-10-12 | Anguilla | 15041 | 1329.0 | 3 | NaN | 3.0 | NaN | 0.0 | . 427 2020-10-12 | Solomon Islands | 691518 | 96.0 | 2 | NaN | NaN | NaN | 2.0 | . 428 rows × 9 columns . country_name = &#39;Bangladesh&#39; country_df = worldometer_df.loc[worldometer_df[&#39;Country&#39;] == country_name, :].reset_index(drop=True) country_df . Date Country Population Total Tests Total Cases Total Deaths Total Recovered Serious or Critical Active Cases . 0 2020-10-11 | Bangladesh | 165151528 | 2070995.0 | 378266 | 5524.0 | 292860.0 | NaN | 79882.0 | . 1 2020-10-12 | Bangladesh | 165151528 | 2084222.0 | 379738 | 5555.0 | 294391.0 | NaN | 79792.0 | . selected_date = datetime.strptime(&#39;10/11/2020&#39;, &#39;%d/%m/%Y&#39;) selected_date_df = worldometer_df.loc[worldometer_df[&#39;Date&#39;] == selected_date.strftime(&#39;%Y-%m-%d&#39;), :].reset_index(drop=True) selected_date_df . Date Country Population Total Tests Total Cases Total Deaths Total Recovered Serious or Critical Active Cases . last_date = datetime.strptime(&#39;12/10/2020&#39;, &#39;%d/%m/%Y&#39;) last_date_df = worldometer_df.loc[worldometer_df[&#39;Date&#39;] == last_date.strftime(&#39;%Y-%m-%d&#39;), :].reset_index(drop=True) last_date_df . Date Country Population Total Tests Total Cases Total Deaths Total Recovered Serious or Critical Active Cases . 0 2020-10-12 | USA | 331552784 | 119497624.0 | 8037789 | 220011.0 | 5184615.0 | 14914.0 | 2633163.0 | . 1 2020-10-12 | India | 1383826697 | 87872093.0 | 7173565 | 109894.0 | 6224792.0 | 8944.0 | 838879.0 | . 2 2020-10-12 | Brazil | 212986866 | 17900000.0 | 5103408 | 150709.0 | 4495269.0 | 8318.0 | 457430.0 | . 3 2020-10-12 | Russia | 145952340 | 51191309.0 | 1312310 | 22722.0 | 1024235.0 | 2300.0 | 265353.0 | . 4 2020-10-12 | Colombia | 51035485 | 4202181.0 | 919083 | 27985.0 | 798396.0 | 2220.0 | 92702.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 209 2020-10-12 | Montserrat | 4993 | 483.0 | 13 | 1.0 | 12.0 | NaN | 0.0 | . 210 2020-10-12 | Falkland Islands | 3508 | 2682.0 | 13 | NaN | 13.0 | NaN | 0.0 | . 211 2020-10-12 | Western Sahara | 601379 | NaN | 10 | 1.0 | 8.0 | NaN | 1.0 | . 212 2020-10-12 | Anguilla | 15041 | 1329.0 | 3 | NaN | 3.0 | NaN | 0.0 | . 213 2020-10-12 | Solomon Islands | 691518 | 96.0 | 2 | NaN | NaN | NaN | 2.0 | . 214 rows × 9 columns . last_date_df[&#39;Case Fatality Ratio&#39;] = last_date_df[&#39;Total Deaths&#39;] / last_date_df[&#39;Total Cases&#39;] plt.figure(figsize=(12,8)) plt.hist(100 * np.array(last_date_df[&#39;Case Fatality Ratio&#39;]), bins=np.arange(35)) plt.xlabel(&#39;Death Rate (%)&#39;, fontsize=16) plt.ylabel(&#39;Number of Countries&#39;, fontsize=16) plt.title(&#39;Histogram of Death Rates for various Countries&#39;, fontsize=18) plt.show() . min_number_of_cases = 1000 greatly_affected_df = last_date_df.loc[last_date_df[&#39;Total Cases&#39;] &gt; min_number_of_cases,:] plt.figure(figsize=(12,8)) plt.hist(100 * np.array(greatly_affected_df[&#39;Case Fatality Ratio&#39;]), bins=np.arange(35)) plt.xlabel(&#39;Death Rate (%)&#39;, fontsize=16) plt.ylabel(&#39;Number of Countries&#39;, fontsize=16) plt.title(&#39;Histogram of Death Rates for various Countries&#39;, fontsize=18) plt.show() . last_date_df[&#39;Num Tests per Positive Case&#39;] = last_date_df[&#39;Total Tests&#39;] / last_date_df[&#39;Total Cases&#39;] min_number_of_cases = 1000 greatly_affected_df = last_date_df.loc[last_date_df[&#39;Total Cases&#39;] &gt; min_number_of_cases,:] x_axis_limit = 80 death_rate_percent = 100 * np.array(greatly_affected_df[&#39;Case Fatality Ratio&#39;]) num_test_per_positive = np.array(greatly_affected_df[&#39;Num Tests per Positive Case&#39;]) num_test_per_positive[num_test_per_positive &gt; x_axis_limit] = x_axis_limit total_num_deaths = np.array(greatly_affected_df[&#39;Total Deaths&#39;]) population = np.array(greatly_affected_df[&#39;Population&#39;]) plt.figure(figsize=(16,12)) plt.scatter(x=num_test_per_positive, y=death_rate_percent, s=0.5*np.power(np.log(1+population),2), c=np.log10(1+total_num_deaths)) plt.colorbar() plt.ylabel(&#39;Death Rate (%)&#39;, fontsize=16) plt.xlabel(&#39;Number of Tests per Positive Case&#39;, fontsize=16) plt.title(&#39;Death Rate as function of Testing Quality&#39;, fontsize=18) plt.xlim(-1, x_axis_limit + 12) plt.ylim(-0.2,17) # plot on top of the figure the names of the #countries_to_display = greatly_affected_df[&#39;Country&#39;].unique().tolist() countries_to_display = [&#39;USA&#39;, &#39;Russia&#39;, &#39;Spain&#39;, &#39;Bangladesh&#39;, &#39;Brazil&#39;, &#39;UK&#39;, &#39;Italy&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;India&#39;, &#39;Canada&#39;, &#39;Belgium&#39;, &#39;Mexico&#39;, &#39;Netherlands&#39;, &#39;Sweden&#39;, &#39;Portugal&#39;, &#39;UAE&#39;, &#39;Poland&#39;, &#39;Indonesia&#39;, &#39;Romania&#39;, &#39;Israel&#39;,&#39;Thailand&#39;,&#39;Kyrgyzstan&#39;,&#39;El Salvador&#39;, &#39;S. Korea&#39;, &#39;Denmark&#39;, &#39;Serbia&#39;, &#39;Norway&#39;, &#39;Algeria&#39;, &#39;Bahrain&#39;,&#39;Slovenia&#39;, &#39;Greece&#39;,&#39;Cuba&#39;,&#39;Hong Kong&#39;,&#39;Lithuania&#39;, &#39;Australia&#39;, &#39;Morocco&#39;, &#39;Malaysia&#39;, &#39;Nigeria&#39;, &#39;Moldova&#39;, &#39;Ghana&#39;, &#39;Armenia&#39;, &#39;Bolivia&#39;, &#39;Iraq&#39;, &#39;Hungary&#39;, &#39;Cameroon&#39;, &#39;Azerbaijan&#39;] for country_name in countries_to_display: country_index = greatly_affected_df.index[greatly_affected_df[&#39;Country&#39;] == country_name] plt.text(x=num_test_per_positive[country_index] + 0.5, y=death_rate_percent[country_index] + 0.2, s=country_name, fontsize=10) plt.show() . posx and posy should be finite values posx and posy should be finite values . good_testing_threshold = 300 good_testing_df = greatly_affected_df.loc[greatly_affected_df[&#39;Num Tests per Positive Case&#39;] &gt; good_testing_threshold,:] good_testing_df . Date Country Population Total Tests Total Cases Total Deaths Total Recovered Serious or Critical Active Cases Case Fatality Ratio Num Tests per Positive Case . 48 2020-10-12 | China | 1439323776 | 160000000.0 | 85578 | 4634.0 | 80714.0 | NaN | 230.0 | 0.054149 | 1869.639393 | . 123 2020-10-12 | Hong Kong | 7514161 | 3473928.0 | 5194 | 105.0 | 4921.0 | 8.0 | 168.0 | 0.020216 | 668.834809 | . 158 2020-10-12 | New Zealand | 5002100 | 1002790.0 | 1871 | 25.0 | 1801.0 | NaN | 45.0 | 0.013362 | 535.964725 | . 164 2020-10-12 | Vietnam | 97585632 | 1246480.0 | 1110 | 35.0 | 1025.0 | NaN | 50.0 | 0.031532 | 1122.954955 | . estimated_death_rate_percent = 100 * good_testing_df[&#39;Total Deaths&#39;].sum() / good_testing_df[&#39;Total Cases&#39;].sum() print(&#39;Death Rate only for &quot;good testing countries&quot; is %.2f%s&#39; %(estimated_death_rate_percent,&#39;%&#39;)) . Death Rate only for &#34;good testing countries&#34; is 5.12% .",
            "url": "https://sakibb019.github.io/Portfolio/2021/09/23/Covid_19_Analysis.html",
            "relUrl": "/2021/09/23/Covid_19_Analysis.html",
            "date": " • Sep 23, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Human Activity Recognition using Machine Learning",
            "content": "import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import warnings warnings.filterwarnings(&quot;ignore&quot;) . train = pd.read_csv(&quot;train-1.csv&quot;) test = pd.read_csv(&quot;test.csv&quot;) . train[&#39;Data&#39;] = &#39;Train&#39; test[&#39;Data&#39;] = &#39;Test&#39; both = pd.concat([train, test], axis=0).reset_index(drop=True) both[&#39;subject&#39;] = &#39;#&#39; + both[&#39;subject&#39;].astype(str) . train.shape, test.shape . ((7352, 564), (2947, 564)) . both.head() . tBodyAcc-mean()-X tBodyAcc-mean()-Y tBodyAcc-mean()-Z tBodyAcc-std()-X tBodyAcc-std()-Y tBodyAcc-std()-Z tBodyAcc-mad()-X tBodyAcc-mad()-Y tBodyAcc-mad()-Z tBodyAcc-max()-X ... angle(tBodyAccMean,gravity) angle(tBodyAccJerkMean),gravityMean) angle(tBodyGyroMean,gravityMean) angle(tBodyGyroJerkMean,gravityMean) angle(X,gravityMean) angle(Y,gravityMean) angle(Z,gravityMean) subject Activity Data . 0 0.288585 | -0.020294 | -0.132905 | -0.995279 | -0.983111 | -0.913526 | -0.995112 | -0.983185 | -0.923527 | -0.934724 | ... | -0.112754 | 0.030400 | -0.464761 | -0.018446 | -0.841247 | 0.179941 | -0.058627 | #1 | STANDING | Train | . 1 0.278419 | -0.016411 | -0.123520 | -0.998245 | -0.975300 | -0.960322 | -0.998807 | -0.974914 | -0.957686 | -0.943068 | ... | 0.053477 | -0.007435 | -0.732626 | 0.703511 | -0.844788 | 0.180289 | -0.054317 | #1 | STANDING | Train | . 2 0.279653 | -0.019467 | -0.113462 | -0.995380 | -0.967187 | -0.978944 | -0.996520 | -0.963668 | -0.977469 | -0.938692 | ... | -0.118559 | 0.177899 | 0.100699 | 0.808529 | -0.848933 | 0.180637 | -0.049118 | #1 | STANDING | Train | . 3 0.279174 | -0.026201 | -0.123283 | -0.996091 | -0.983403 | -0.990675 | -0.997099 | -0.982750 | -0.989302 | -0.938692 | ... | -0.036788 | -0.012892 | 0.640011 | -0.485366 | -0.848649 | 0.181935 | -0.047663 | #1 | STANDING | Train | . 4 0.276629 | -0.016570 | -0.115362 | -0.998139 | -0.980817 | -0.990482 | -0.998321 | -0.979672 | -0.990441 | -0.942469 | ... | 0.123320 | 0.122542 | 0.693578 | -0.615971 | -0.847865 | 0.185151 | -0.043892 | #1 | STANDING | Train | . 5 rows × 564 columns . both.dtypes.value_counts() . float64 561 object 3 dtype: int64 . def basic_details(df): b = pd.DataFrame() b[&#39;Missing value&#39;] = df.isnull().sum() b[&#39;N unique value&#39;] = df.nunique() b[&#39;dtype&#39;] = df.dtypes return b basic_details(both) . Missing value N unique value dtype . tBodyAcc-mean()-X 0 | 10292 | float64 | . tBodyAcc-mean()-Y 0 | 10299 | float64 | . tBodyAcc-mean()-Z 0 | 10293 | float64 | . tBodyAcc-std()-X 0 | 10295 | float64 | . tBodyAcc-std()-Y 0 | 10297 | float64 | . ... ... | ... | ... | . angle(Y,gravityMean) 0 | 10299 | float64 | . angle(Z,gravityMean) 0 | 10299 | float64 | . subject 0 | 30 | object | . Activity 0 | 6 | object | . Data 0 | 2 | object | . 564 rows × 3 columns . activity = both[&#39;Activity&#39;] label_counts = activity.value_counts() plt.figure(figsize= (12, 8)) plt.bar(label_counts.index, label_counts) . &lt;BarContainer object of 6 artists&gt; . Data = both[&#39;Data&#39;] Subject = both[&#39;subject&#39;] train = both.copy() train = train.drop([&#39;Data&#39;,&#39;subject&#39;,&#39;Activity&#39;], axis =1) . from sklearn.preprocessing import StandardScaler slc = StandardScaler() train = slc.fit_transform(train) # dimensionality reduction from sklearn.decomposition import PCA pca = PCA(n_components=0.9, random_state=0) train = pca.fit_transform(train) . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(train, activity, test_size = 0.2, random_state = 0) . num_folds = 10 seed = 0 scoring = &#39;accuracy&#39; results = {} accuracy = {} . from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import confusion_matrix, accuracy_score, classification_report from sklearn.model_selection import KFold, cross_val_score model = KNeighborsClassifier(algorithm= &#39;auto&#39;, n_neighbors= 8, p= 1, weights= &#39;distance&#39;) _ = cross_val_score(model, X_train, y_train, cv=10, scoring=scoring) results[&quot;GScv&quot;] = (_.mean(), _.std()) model.fit(X_train, y_train) y_predict = model.predict(X_test) accuracy[&quot;GScv&quot;] = accuracy_score(y_test, y_predict) print(classification_report(y_test, y_predict)) cm= confusion_matrix(y_test, y_predict) sns.heatmap(cm, annot=True) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:670: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_folds = np.zeros(n_samples, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations test_mask = np.zeros(_num_samples(X), dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations self._y = np.empty(y.shape, dtype=np.int) . precision recall f1-score support LAYING 1.00 1.00 1.00 377 SITTING 0.92 0.87 0.90 364 STANDING 0.89 0.93 0.91 390 WALKING 0.96 0.99 0.97 335 WALKING_DOWNSTAIRS 0.99 0.95 0.97 278 WALKING_UPSTAIRS 0.98 0.98 0.98 316 accuracy 0.95 2060 macro avg 0.96 0.95 0.95 2060 weighted avg 0.95 0.95 0.95 2060 . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f27240e4f90&gt; .",
            "url": "https://sakibb019.github.io/Portfolio/2021/08/07/Human_Activity_Recognition_using_Machine_Learning.html",
            "relUrl": "/2021/08/07/Human_Activity_Recognition_using_Machine_Learning.html",
            "date": " • Aug 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "English to German language translator Apps Using the Python programming Language",
            "content": "Install Dependencies . pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html . Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html Collecting torch==1.8.1+cu111 Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB) |█████████████▌ | 834.1 MB 1.3 MB/s eta 0:14:31tcmalloc: large alloc 1147494400 bytes == 0x5558e0176000 @ 0x7fc27343a615 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a676bf40 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a66f9b99 0x5558a673ce79 0x5558a66f87b2 0x5558a676be65 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a6767b0e 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 |█████████████████ | 1055.7 MB 1.4 MB/s eta 0:10:54tcmalloc: large alloc 1434370048 bytes == 0x5559247cc000 @ 0x7fc27343a615 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a676bf40 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a66f9b99 0x5558a673ce79 0x5558a66f87b2 0x5558a676be65 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a6767b0e 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 |█████████████████████▋ | 1336.2 MB 1.3 MB/s eta 0:08:21tcmalloc: large alloc 1792966656 bytes == 0x5558a95fe000 @ 0x7fc27343a615 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a676bf40 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a66f9b99 0x5558a673ce79 0x5558a66f87b2 0x5558a676be65 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a6767b0e 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 |███████████████████████████▎ | 1691.1 MB 1.3 MB/s eta 0:03:52tcmalloc: large alloc 2241208320 bytes == 0x5559143e6000 @ 0x7fc27343a615 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a676bf40 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a67eaa56 0x5558a6767fb3 0x5558a66f9b99 0x5558a673ce79 0x5558a66f87b2 0x5558a676be65 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a6767b0e 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x555999d48000 @ 0x7fc2734391e7 0x5558a672aae7 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 tcmalloc: large alloc 2477727744 bytes == 0x555a84426000 @ 0x7fc27343a615 0x5558a66f502c 0x5558a67d517a 0x5558a66f7e4d 0x5558a67e9c0d 0x5558a676c0d8 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a6767d67 0x5558a66f965a 0x5558a6767d67 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f973a 0x5558a676893b 0x5558a6766c35 0x5558a66f9dd1 |████████████████████████████████| 1982.2 MB 1.2 kB/s Collecting torchvision==0.9.1+cu111 Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB) |████████████████████████████████| 17.6 MB 48 kB/s Collecting torchaudio===0.8.1 Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB) |████████████████████████████████| 1.9 MB 8.0 MB/s Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5) Requirement already satisfied: pillow&gt;=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2) Installing collected packages: torch, torchvision, torchaudio Attempting uninstall: torch Found existing installation: torch 1.9.0+cu102 Uninstalling torch-1.9.0+cu102: Successfully uninstalled torch-1.9.0+cu102 Attempting uninstall: torchvision Found existing installation: torchvision 0.10.0+cu102 Uninstalling torchvision-0.10.0+cu102: Successfully uninstalled torchvision-0.10.0+cu102 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1+cu111 which is incompatible. Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111 . !pip install transformers ipywidgets gradio --upgrade . Collecting transformers Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB) |████████████████████████████████| 2.6 MB 7.3 MB/s Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.3) Collecting gradio Downloading gradio-2.2.8-py3-none-any.whl (2.2 MB) |████████████████████████████████| 2.2 MB 52.6 MB/s Collecting sacremoses Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB) |████████████████████████████████| 895 kB 56.1 MB/s Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0) Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1) Collecting tokenizers&lt;0.11,&gt;=0.10.1 Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB) |████████████████████████████████| 3.3 MB 54.3 MB/s Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1) Collecting pyyaml&gt;=5.1 Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB) |████████████████████████████████| 636 kB 61.1 MB/s Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20) Collecting huggingface-hub==0.0.12 Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB) Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12) Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12-&gt;transformers) (3.7.4.3) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;transformers) (2.4.7) Requirement already satisfied: nbformat&gt;=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3) Requirement already satisfied: traitlets&gt;=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.0.5) Requirement already satisfied: ipython&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0) Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1) Requirement already satisfied: jupyterlab-widgets&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.0) Requirement already satisfied: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1) Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (5.3.5) Requirement already satisfied: tornado&gt;=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (5.1.1) Requirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (57.2.0) Requirement already satisfied: simplegeneric&gt;0.8 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (0.8.1) Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (0.7.5) Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (4.8.0) Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (4.4.2) Requirement already satisfied: prompt-toolkit&lt;2.0.0,&gt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (1.0.18) Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets) (2.6.1) Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (0.2.0) Requirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (2.6.0) Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (4.7.1) Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;ipython&gt;=4.0.0-&gt;ipywidgets) (1.15.0) Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;ipython&gt;=4.0.0-&gt;ipywidgets) (0.2.5) Requirement already satisfied: notebook&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0-&gt;ipywidgets) (5.3.1) Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (5.6.1) Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.7.1) Requirement already satisfied: terminado&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.10.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (2.11.3) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (2.8.1) Requirement already satisfied: pyzmq&gt;=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (22.1.0) Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&gt;=0.8.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.7.0) Collecting flask-cachebuster Downloading Flask-CacheBuster-1.0.0.tar.gz (3.1 kB) Collecting Flask-Login Downloading Flask_Login-0.5.0-py2.py3-none-any.whl (16 kB) Collecting analytics-python Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2) Collecting Flask-Cors&gt;=3.0.8 Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB) Collecting pycryptodome Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB) |████████████████████████████████| 1.9 MB 56.9 MB/s Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.1) Requirement already satisfied: Flask&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4) Collecting paramiko Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB) |████████████████████████████████| 206 kB 73.7 MB/s Collecting ffmpy Downloading ffmpy-0.3.0.tar.gz (4.8 kB) Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2) Collecting markdown2 Downloading markdown2-2.4.0-py2.py3-none-any.whl (34 kB) Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (7.1.2) Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (1.0.1) Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (1.1.0) Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (2.0.1) Collecting monotonic&gt;=1.5 Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB) Collecting backoff==1.10.0 Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (1.24.3) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2021.5.30) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (3.0.4) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers) (3.5.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (1.3.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (0.10.0) Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.3) Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.7.1) Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.4.3) Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (3.3.0) Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.4) Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.5.0) Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.5.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;gradio) (2018.9) Collecting cryptography&gt;=2.5 Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB) |████████████████████████████████| 3.2 MB 51.4 MB/s Collecting pynacl&gt;=1.0.1 Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB) |████████████████████████████████| 961 kB 58.4 MB/s Collecting bcrypt&gt;=3.1.3 Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB) |████████████████████████████████| 63 kB 2.5 MB/s Requirement already satisfied: cffi&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt&gt;=3.1.3-&gt;paramiko-&gt;gradio) (1.14.6) Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.1-&gt;bcrypt&gt;=3.1.3-&gt;paramiko-&gt;gradio) (2.20) Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers) (1.0.1) Building wheels for collected packages: ffmpy, flask-cachebuster Building wheel for ffmpy (setup.py) ... done Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4709 sha256=5b58164b1a5180b64f8201b2e5555acd322da52b0ad103e867984089b981a542 Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6 Building wheel for flask-cachebuster (setup.py) ... done Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-py3-none-any.whl size=3372 sha256=af857e6120b90d7b074ddf5cae6e68013f7d312b5680de01702361b4d0ef427e Stored in directory: /root/.cache/pip/wheels/28/c0/c4/44687421dab41455be93112bd1b0dee1f3c5a9aa27bee63708 Successfully built ffmpy flask-cachebuster Installing collected packages: pynacl, monotonic, cryptography, bcrypt, backoff, tokenizers, sacremoses, pyyaml, pycryptodome, paramiko, markdown2, huggingface-hub, Flask-Login, Flask-Cors, flask-cachebuster, ffmpy, analytics-python, transformers, gradio Attempting uninstall: pyyaml Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 Successfully installed Flask-Cors-3.0.10 Flask-Login-0.5.0 analytics-python-1.4.0 backoff-1.10.0 bcrypt-3.2.0 cryptography-3.4.7 ffmpy-0.3.0 flask-cachebuster-1.0.0 gradio-2.2.8 huggingface-hub-0.0.12 markdown2-2.4.0 monotonic-1.6 paramiko-2.7.2 pycryptodome-3.10.1 pynacl-1.4.0 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1 . Load up Pipeline . import gradio as gf # UI library from transformers import pipeline # Transformers pipeline . translation_pipeline = pipeline(&#39;translation_en_to_de&#39;) . . translation_pipeline(&#39;My name is Sakib&#39;) . [{&#39;translation_text&#39;: &#39;Mein Name ist Sakib&#39;}] . def translate_transformers(from_text): results = translation_pipeline(from_text) return results[0][&#39;translation_text&#39;] . translate_transformers:(&#39;My name is Sakib&#39;) . pip install gradio . Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (2.2.8) Requirement already satisfied: Flask&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4) Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2) Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5) Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.7.2) Requirement already satisfied: Flask-Cors&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from gradio) (3.0.10) Requirement already satisfied: flask-cachebuster in /usr/local/lib/python3.7/dist-packages (from gradio) (1.0.0) Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0) Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.10.1) Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5) Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2) Requirement already satisfied: Flask-Login in /usr/local/lib/python3.7/dist-packages (from gradio) (0.5.0) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.1) Requirement already satisfied: markdown2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.4.0) Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (1.0.1) Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (1.1.0) Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (2.11.3) Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.1-&gt;gradio) (7.1.2) Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors&gt;=3.0.8-&gt;gradio) (1.15.0) Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;Flask&gt;=1.1.1-&gt;gradio) (2.0.1) Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python-&gt;gradio) (1.10.0) Requirement already satisfied: monotonic&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python-&gt;gradio) (1.6) Requirement already satisfied: python-dateutil&gt;2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python-&gt;gradio) (2.8.1) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (2021.5.30) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (1.24.3) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (0.10.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (1.3.1) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (2.4.7) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;gradio) (2018.9) Requirement already satisfied: cryptography&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko-&gt;gradio) (3.4.7) Requirement already satisfied: pynacl&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko-&gt;gradio) (1.4.0) Requirement already satisfied: bcrypt&gt;=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko-&gt;gradio) (3.2.0) Requirement already satisfied: cffi&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt&gt;=3.1.3-&gt;paramiko-&gt;gradio) (1.14.6) Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.1-&gt;bcrypt&gt;=3.1.3-&gt;paramiko-&gt;gradio) (2.20) . Create Gradio Function and Interface . import gradio as gr def greet(name): return &quot;Hello &quot; + name + &quot;!!&quot; iface = gr.Interface(fn=greet, inputs=&quot;text&quot;, outputs=&quot;text&quot;) iface.launch() . Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()` This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!) Running on External URL: https://54425.gradio.app Interface loading below... . (&lt;Flask &#39;gradio.networking&#39;&gt;, &#39;http://127.0.0.1:7860/&#39;, &#39;https://54425.gradio.app&#39;) . interface = gr.Interface(fn=translate_transformers, inputs=gr.inputs.Textbox(lines=2, placeholder= &#39;Text to Translate&#39;), outputs=&#39;text&#39;) . interface.launch() . Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()` This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!) Running on External URL: https://35025.gradio.app Interface loading below... . (&lt;Flask &#39;gradio.networking&#39;&gt;, &#39;http://127.0.0.1:7861/&#39;, &#39;https://35025.gradio.app&#39;) .",
            "url": "https://sakibb019.github.io/Portfolio/2021/08/07/English-to-German-language-translation.html",
            "relUrl": "/2021/08/07/English-to-German-language-translation.html",
            "date": " • Aug 7, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Title",
            "content": "import tensorflow as tf from tensorflow import keras fashion_mnist = keras.datasets.fashion_mnist (X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 1s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 8192/5148 [===============================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step . X_train_full.shape . (60000, 28, 28) . X_train_full.dtype . dtype(&#39;uint8&#39;) . X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255. y_valid, y_train = y_train_full[:5000], y_train_full[5000:] X_test = X_test / 255. . plt.imshow(X_train[0], cmap=&quot;binary&quot;) plt.axis(&#39;off&#39;) plt.show() . y_train . array([4, 0, 7, ..., 3, 0, 5], dtype=uint8) . class_names = [&quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;] . class_names[y_train[0]] . &#39;Coat&#39; . X_valid.shape . (5000, 28, 28) . X_valid.shape . (5000, 28, 28) . n_rows = 4 n_cols = 10 plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2)) for row in range(n_rows): for col in range(n_cols): index = n_cols * row + col plt.subplot(n_rows, n_cols, index + 1) plt.imshow(X_train[index], cmap=&quot;binary&quot;, interpolation=&quot;nearest&quot;) plt.axis(&#39;off&#39;) plt.title(class_names[y_train[index]], fontsize=12) plt.subplots_adjust(wspace=0.2, hspace=0.5) save_fig(&#39;fashion_mnist_plot&#39;, tight_layout=False) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-23-5f1e97bb1426&gt; in &lt;module&gt; 10 plt.title(class_names[y_train[index]], fontsize=12) 11 plt.subplots_adjust(wspace=0.2, hspace=0.5) &gt; 12 save_fig(&#39;fashion_mnist_plot&#39;, tight_layout=False) 13 plt.show() NameError: name &#39;save_fig&#39; is not defined . model = keras.models.Sequential() model.add(keras.layers.Flatten(input_shape=[28, 28])) model.add(keras.layers.Dense(300, activation=&quot;relu&quot;)) model.add(keras.layers.Dense(100, activation=&quot;relu&quot;)) model.add(keras.layers.Dense(10, activation=&quot;softmax&quot;)) keras.backend.clear_session() np.random.seed(42) tf.random.set_seed(42) . AttributeError Traceback (most recent call last) &lt;ipython-input-25-e54bf78ebc8b&gt; in &lt;module&gt; 6 keras.backend.clear_session() 7 np.random.seed(42) -&gt; 8 tf.random.set_seed(42) AttributeError: module &#39;tensorflow._api.v1.random&#39; has no attribute &#39;set_seed&#39; . model = keras.models.Sequential([ keras.layers.Flatten(input_shape=[28, 28]), keras.layers.Dense(300, activation=&quot;relu&quot;), keras.layers.Dense(100, activation=&quot;relu&quot;), keras.layers.Dense(10, activation=&quot;softmax&quot;) ]) model.layers . [&lt;tensorflow.python.keras.layers.core.Flatten at 0x7f5f5df7b610&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5df7b590&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5df7b710&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5e190750&gt;] . model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 300) 235500 _________________________________________________________________ dense_1 (Dense) (None, 100) 30100 _________________________________________________________________ dense_2 (Dense) (None, 10) 1010 ================================================================= Total params: 266,610 Trainable params: 266,610 Non-trainable params: 0 _________________________________________________________________ . hidden1 = model.layers[1] hidden1.name . &#39;dense&#39; . model.get_layer(hidden1.name) is hidden1 . True . weights, biases = hidden1.get_weights() . biases . array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32) . model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=&quot;sgd&quot;, metrics=[&quot;accuracy&quot;]) . history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid)) . Train on 55000 samples, validate on 5000 samples Epoch 1/30 55000/55000 [==============================] - 22s 399us/sample - loss: 0.7050 - acc: 0.7663 - val_loss: 0.4985 - val_acc: 0.8366 Epoch 2/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.4845 - acc: 0.8310 - val_loss: 0.4563 - val_acc: 0.8426 Epoch 3/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.4408 - acc: 0.8468 - val_loss: 0.4093 - val_acc: 0.8610 Epoch 4/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.4148 - acc: 0.8551 - val_loss: 0.4008 - val_acc: 0.8656 Epoch 5/30 55000/55000 [==============================] - 21s 384us/sample - loss: 0.3948 - acc: 0.8615 - val_loss: 0.3795 - val_acc: 0.8696 Epoch 6/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3792 - acc: 0.8668 - val_loss: 0.3749 - val_acc: 0.8722 Epoch 7/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3649 - acc: 0.8714 - val_loss: 0.3761 - val_acc: 0.8710 Epoch 8/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3537 - acc: 0.8757 - val_loss: 0.3781 - val_acc: 0.8688 Epoch 9/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3428 - acc: 0.8790 - val_loss: 0.3459 - val_acc: 0.8806 Epoch 10/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3341 - acc: 0.8824 - val_loss: 0.3710 - val_acc: 0.8702 Epoch 11/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3260 - acc: 0.8839 - val_loss: 0.3332 - val_acc: 0.8834 Epoch 12/30 55000/55000 [==============================] - 21s 389us/sample - loss: 0.3173 - acc: 0.8873 - val_loss: 0.3409 - val_acc: 0.8792 Epoch 13/30 55000/55000 [==============================] - 22s 393us/sample - loss: 0.3092 - acc: 0.8901 - val_loss: 0.3482 - val_acc: 0.8780 Epoch 14/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3039 - acc: 0.8902 - val_loss: 0.3219 - val_acc: 0.8864 Epoch 15/30 55000/55000 [==============================] - 21s 384us/sample - loss: 0.2959 - acc: 0.8939 - val_loss: 0.3214 - val_acc: 0.8852 Epoch 16/30 55000/55000 [==============================] - 21s 381us/sample - loss: 0.2903 - acc: 0.8957 - val_loss: 0.3333 - val_acc: 0.8830 Epoch 17/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.2847 - acc: 0.8980 - val_loss: 0.3232 - val_acc: 0.8824 Epoch 18/30 55000/55000 [==============================] - 21s 389us/sample - loss: 0.2802 - acc: 0.8997 - val_loss: 0.3286 - val_acc: 0.8780 Epoch 19/30 55000/55000 [==============================] - 21s 387us/sample - loss: 0.2740 - acc: 0.9018 - val_loss: 0.3057 - val_acc: 0.8892 Epoch 20/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2692 - acc: 0.9037 - val_loss: 0.3078 - val_acc: 0.8890 Epoch 21/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2652 - acc: 0.9053 - val_loss: 0.3153 - val_acc: 0.8864 Epoch 22/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2588 - acc: 0.9077 - val_loss: 0.3196 - val_acc: 0.8846 Epoch 23/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2556 - acc: 0.9078 - val_loss: 0.3162 - val_acc: 0.8868 Epoch 24/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.2507 - acc: 0.9101 - val_loss: 0.3081 - val_acc: 0.8880 Epoch 25/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2462 - acc: 0.9126 - val_loss: 0.3017 - val_acc: 0.8894 Epoch 26/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2424 - acc: 0.9133 - val_loss: 0.3277 - val_acc: 0.8830 Epoch 27/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.2395 - acc: 0.9148 - val_loss: 0.3006 - val_acc: 0.8904 Epoch 28/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2348 - acc: 0.9160 - val_loss: 0.3030 - val_acc: 0.8914 Epoch 29/30 55000/55000 [==============================] - 20s 372us/sample - loss: 0.2306 - acc: 0.9178 - val_loss: 0.2998 - val_acc: 0.8918 Epoch 30/30 55000/55000 [==============================] - 21s 373us/sample - loss: 0.2273 - acc: 0.9189 - val_loss: 0.3016 - val_acc: 0.8948 . import pandas as pd pd.DataFrame(history.history).plot(figsize=(8, 5)) plt.grid(True) plt.gca().set_ylim(0, 1) save_fig(&quot;keras_learning_curves_plot&quot;) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-35-e5ab1d7e7f53&gt; in &lt;module&gt; 4 plt.grid(True) 5 plt.gca().set_ylim(0, 1) -&gt; 6 save_fig(&#34;keras_learning_curves_plot&#34;) 7 plt.show() NameError: name &#39;save_fig&#39; is not defined . model.evaluate(X_test, y_test) . 10000/10000 [==============================] - 1s 128us/sample - loss: 0.3316 - acc: 0.8852 . [0.3315748940348625, 0.8852] . X_new = X_test[:3] y_proba = model.predict(X_new) y_proba.round(2) . array([[0. , 0. , 0. , 0. , 0. , 0.01, 0. , 0.03, 0. , 0.97], [0. , 0. , 0.98, 0. , 0.02, 0. , 0. , 0. , 0. , 0. ], [0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32) . y_pred = model.predict_classes(X_new) y_pred . array([9, 2, 1]) . np.array(class_names)[y_pred] . array([&#39;Ankle boot&#39;, &#39;Pullover&#39;, &#39;Trouser&#39;], dtype=&#39;&lt;U11&#39;) . y_new = y_test[:3] plt.figure(figsize=(7.2, 2.4)) for index, image in enumerate(X_new): plt.subplot(1, 3, index + 1) plt.imshow(image, cmap=&quot;binary&quot;, interpolation=&quot;nearest&quot;) plt.axis(&#39;off&#39;) plt.title(class_names[y_test[index]], fontsize=12) plt.subplots_adjust(wspace=0.2, hspace=0.5) save_fig(&#39;fashion_mnist_images_plot&#39;, tight_layout=False) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-40-dd332162bb4a&gt; in &lt;module&gt; 7 plt.title(class_names[y_test[index]], fontsize=12) 8 plt.subplots_adjust(wspace=0.2, hspace=0.5) -&gt; 9 save_fig(&#39;fashion_mnist_images_plot&#39;, tight_layout=False) 10 plt.show() NameError: name &#39;save_fig&#39; is not defined .",
            "url": "https://sakibb019.github.io/Portfolio/2021/08/06/Image-classifiaction.html",
            "relUrl": "/2021/08/06/Image-classifiaction.html",
            "date": " • Aug 6, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Title",
            "content": ". Employee Turnover Prediction using Python . import pandas as pd hr = pd.read_csv(&#39;HR_comma_sep.csv&#39;) col_names = hr.columns.tolist() print(&quot;Column names:&quot;) print(col_names) print(&quot; nSample data:&quot;) hr.head() . Column names: [&#39;satisfaction_level&#39;, &#39;last_evaluation&#39;, &#39;number_project&#39;, &#39;average_montly_hours&#39;, &#39;time_spend_company&#39;, &#39;Work_accident&#39;, &#39;left&#39;, &#39;promotion_last_5years&#39;, &#39;sales&#39;, &#39;salary&#39;] Sample data: . satisfaction_level last_evaluation number_project average_montly_hours time_spend_company Work_accident left promotion_last_5years sales salary . 0 0.38 | 0.53 | 2 | 157 | 3 | 0 | 1 | 0 | sales | low | . 1 0.80 | 0.86 | 5 | 262 | 6 | 0 | 1 | 0 | sales | medium | . 2 0.11 | 0.88 | 7 | 272 | 4 | 0 | 1 | 0 | sales | medium | . 3 0.72 | 0.87 | 5 | 223 | 5 | 0 | 1 | 0 | sales | low | . 4 0.37 | 0.52 | 2 | 159 | 3 | 0 | 1 | 0 | sales | low | . hr=hr.rename(columns = {&#39;sales&#39;:&#39;department&#39;}) . hr.shape . (14999, 10) . hr[&#39;department&#39;].unique() . array([&#39;sales&#39;, &#39;accounting&#39;, &#39;hr&#39;, &#39;technical&#39;, &#39;support&#39;, &#39;management&#39;, &#39;IT&#39;, &#39;product_mng&#39;, &#39;marketing&#39;, &#39;RandD&#39;], dtype=object) . import numpy as np hr[&#39;department&#39;]=np.where(hr[&#39;department&#39;] ==&#39;support&#39;, &#39;technical&#39;, hr[&#39;department&#39;]) hr[&#39;department&#39;]=np.where(hr[&#39;department&#39;] ==&#39;IT&#39;, &#39;technical&#39;, hr[&#39;department&#39;]) . cat_vars=[&#39;department&#39;,&#39;salary&#39;] for var in cat_vars: cat_list=&#39;var&#39;+&#39;_&#39;+var cat_list = pd.get_dummies(hr[var], prefix=var) hr1=hr.join(cat_list) hr=hr1 . hr.drop(hr.columns[[8, 9]], axis=1, inplace=True) hr.columns.values . array([&#39;satisfaction_level&#39;, &#39;last_evaluation&#39;, &#39;number_project&#39;, &#39;average_montly_hours&#39;, &#39;time_spend_company&#39;, &#39;Work_accident&#39;, &#39;left&#39;, &#39;promotion_last_5years&#39;, &#39;department_RandD&#39;, &#39;department_accounting&#39;, &#39;department_hr&#39;, &#39;department_management&#39;, &#39;department_marketing&#39;, &#39;department_product_mng&#39;, &#39;department_sales&#39;, &#39;department_technical&#39;, &#39;salary_high&#39;, &#39;salary_low&#39;, &#39;salary_medium&#39;], dtype=object) . hr_vars=hr.columns.values.tolist() y=[&#39;left&#39;] X=[i for i in hr_vars if i not in y] . from sklearn.feature_selection import RFE from sklearn.linear_model import LogisticRegression model = LogisticRegression() rfe = RFE(model, 10) rfe = rfe.fit(hr[X], hr[y]) print(rfe.support_) print(rfe.ranking_) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations method=&#39;lar&#39;, copy_X=True, eps=np.finfo(np.float).eps, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations method=&#39;lar&#39;, copy_X=True, eps=np.finfo(np.float).eps, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations eps=np.finfo(np.float).eps, copy_X=True, fit_path=True, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations eps=np.finfo(np.float).eps, copy_X=True, fit_path=True, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations eps=np.finfo(np.float).eps, positive=False): /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps, /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations eps=np.finfo(np.float).eps, copy_X=True, positive=False): /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations EPS = np.finfo(np.float).eps /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel(). y = column_or_1d(y, warn=True) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py:167: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations support_ = np.ones(n_features, dtype=np.bool) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py:168: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations ranking_ = np.ones(n_features, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . [ True True False False True True True True False True True False False False False True True False] [1 1 3 9 1 1 1 1 5 1 1 6 8 7 4 1 1 2] . cols=[&#39;satisfaction_level&#39;, &#39;last_evaluation&#39;, &#39;time_spend_company&#39;, &#39;Work_accident&#39;, &#39;promotion_last_5years&#39;, &#39;department_RandD&#39;, &#39;department_hr&#39;, &#39;department_management&#39;, &#39;salary_high&#39;, &#39;salary_low&#39;] X=hr[cols] y=hr[&#39;left&#39;] . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) from sklearn.linear_model import LogisticRegression from sklearn import metrics logreg = LogisticRegression() logreg.fit(X_train, y_train) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. FutureWarning) . LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;warn&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;warn&#39;, tol=0.0001, verbose=0, warm_start=False) . from sklearn.metrics import accuracy_score print(&#39;Logistic regression accuracy: {:.3f}&#39;.format(accuracy_score(y_test, logreg.predict(X_test)))) . Logistic regression accuracy: 0.771 . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations indices = (scores &gt; 0).astype(np.int) . from sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier() rf.fit(X_train, y_train) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations from ._gradient_boosting import predict_stages /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations from ._gradient_boosting import predict_stages /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22. &#34;10 in version 0.20 to 100 in 0.22.&#34;, FutureWarning) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/forest.py:489: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_store_unique_indices = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations y_encoded = np.zeros(y.shape, dtype=np.int) . RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False) . print(&#39;Random Forest Accuracy: {:.3f}&#39;.format(accuracy_score(y_test, rf.predict(X_test)))) . Random Forest Accuracy: 0.976 . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations dtype=np.int) . from sklearn.metrics import classification_report print(classification_report(y_test, rf.predict(X_test))) . precision recall f1-score support 0 0.98 0.98 0.98 3462 1 0.95 0.95 0.95 1038 accuracy 0.98 4500 macro avg 0.97 0.97 0.97 4500 weighted avg 0.98 0.98 0.98 4500 . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations dtype=np.int) . import matplotlib import matplotlib.pyplot as plt y_pred = rf.predict(X_test) from sklearn.metrics import confusion_matrix import seaborn as sns forest_cm = metrics.confusion_matrix(y_pred, y_test, [1,0]) sns.heatmap(forest_cm, annot=True, fmt=&#39;.2f&#39;,xticklabels = [&quot;Left&quot;, &quot;Stayed&quot;] , yticklabels = [&quot;Left&quot;, &quot;Stayed&quot;] ) plt.ylabel(&#39;True class&#39;) plt.xlabel(&#39;Predicted class&#39;) plt.title(&#39;Random Forest&#39;) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations dtype=np.int) . Text(0.5, 1, &#39;Random Forest&#39;) . print(classification_report(y_test, logreg.predict(X_test))) . precision recall f1-score support 0 0.81 0.92 0.86 3462 1 0.51 0.26 0.35 1038 accuracy 0.77 4500 macro avg 0.66 0.59 0.60 4500 weighted avg 0.74 0.77 0.74 4500 . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations indices = (scores &gt; 0).astype(np.int) . import matplotlib import matplotlib.pyplot as plt logreg_y_pred = logreg.predict(X_test) logreg_cm = metrics.confusion_matrix(logreg_y_pred, y_test, [1,0]) sns.heatmap(logreg_cm, annot=True, fmt=&#39;.2f&#39;,xticklabels = [&quot;Left&quot;, &quot;Stayed&quot;] , yticklabels = [&quot;Left&quot;, &quot;Stayed&quot;] ) plt.ylabel(&#39;True class&#39;) plt.xlabel(&#39;Predicted class&#39;) plt.title(&#39;Logistic Regression&#39;) . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations indices = (scores &gt; 0).astype(np.int) . Text(0.5, 1, &#39;Logistic Regression&#39;) . import matplotlib import matplotlib.pyplot as plt from sklearn.metrics import roc_auc_score from sklearn.metrics import roc_curve logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test)) fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1]) rf_roc_auc = roc_auc_score(y_test, rf.predict(X_test)) rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1]) plt.figure() plt.plot(fpr, tpr, label=&#39;Logistic Regression (area = %0.2f)&#39; % logit_roc_auc) plt.plot(rf_fpr, rf_tpr, label=&#39;Random Forest (area = %0.2f)&#39; % rf_roc_auc) plt.plot([0, 1], [0, 1],&#39;r--&#39;) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(&#39;False Positive Rate&#39;) plt.ylabel(&#39;True Positive Rate&#39;) plt.title(&#39;Receiver operating characteristic&#39;) plt.legend(loc=&quot;lower right&quot;) plt.show() . /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/linear_model/base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations indices = (scores &gt; 0).astype(np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations dtype=np.int) /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations dtype=np.int) . feature_labels = np.array([&#39;satisfaction_level&#39;, &#39;last_evaluation&#39;, &#39;time_spend_company&#39;, &#39;Work_accident&#39;, &#39;promotion_last_5years&#39;, &#39;department_RandD&#39;, &#39;department_hr&#39;, &#39;department_management&#39;, &#39;salary_high&#39;, &#39;salary_low&#39;]) importance = rf.feature_importances_ feature_indexes_by_importance = importance.argsort() for index in feature_indexes_by_importance: print(&#39;{}-{:.2f}%&#39;.format(feature_labels[index], (importance[index] *100.0))) . promotion_last_5years-0.21% department_management-0.27% department_RandD-0.34% department_hr-0.40% salary_high-0.64% salary_low-1.18% Work_accident-1.76% last_evaluation-18.80% time_spend_company-25.36% satisfaction_level-51.04% .",
            "url": "https://sakibb019.github.io/Portfolio/2021/08/06/Employee-Turnover-Prediction-using-Python.html",
            "relUrl": "/2021/08/06/Employee-Turnover-Prediction-using-Python.html",
            "date": " • Aug 6, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Explore a dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016",
            "content": ". import numpy as np import pandas as pd import seaborn as sns from matplotlib import pyplot as plt . Collecting information about both the data sets . We are going to: . Review the first lines of the data; | Use the describe and info functions to collect statistical information, datatypes, column names and other information | data = pd.read_csv(&#39;../input/athlete-events/athlete_events.csv&#39;) regions = pd.read_csv(&#39;../input/athlete-events/noc_regions.csv&#39;) . data.describe() . data.info() . regions = pd.read_csv(&#39;../input/athlete-events/noc_regions.csv&#39;) regions.head() . Joining the data frames . merged = pd.merge(data, regions, on=&#39;NOC&#39;, how=&#39;left&#39;) merged.head() . Distribution of the age of gold medalists . Let&#8217;s start creating a new data frame including only gold medalists. . goldMedals = merged[(merged.Medal == &#39;Gold&#39;)] goldMedals.head() . I would like to have a plot of the Age to see the distribution but I need to check first if the Age column contains NaN values. . goldMedals.isnull().any() . Let&#8217;s take only the values that are different from NaN. . goldMedals = goldMedals[np.isfinite(goldMedals[&#39;Age&#39;])] . We can now create a countplot to see the result of our work: . plt.figure(figsize=(20, 10)) plt.tight_layout() sns.countplot(goldMedals[&#39;Age&#39;]) plt.title(&#39;Distribution of Gold Medals&#39;) . It seems that we have people with Age greater that 50 with a gold medal: Let&#8217;s know more about those people. . goldMedals[&#39;ID&#39;][goldMedals[&#39;Age&#39;] &gt; 50].count() . 65 people. Wonderul But which disciplines allows you to land a gold medal after your fifties? . We will now create a new dataframe called masterDisciplines in which we will insert this new set of people and then create a visualization with it. . masterDisciplines = goldMedals[&#39;Sport&#39;][goldMedals[&#39;Age&#39;] &gt; 50] plt.figure(figsize=(20, 10)) plt.tight_layout() sns.countplot(masterDisciplines) plt.title(&#39;Gold Medals for Athletes Over 50&#39;) . It seems that our senior gold medalists are shooters, archers, sailors and, above all, horse riders! . It makes sense: I cannot imagine a sprinter making 100 meters in 10 seconds at 55, but who knows! . Women in Athletics . Studying the data we can try to understand how much medals we have only for women in the recent history of the Summer Games. Let&#8217;s create a filtered dataset : . womenInOlympics = merged[(merged.Sex == &#39;F&#39;) &amp; (merged.Season == &#39;Summer&#39;)] womenInOlympics.head(10) . To plot the curve over time, let&#8217;s create a plot in which we put the year (on the x-axis) and count of the number of medals per edition of the games (consider that we will have more medals for the same athlete). . sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=womenInOlympics) plt.title(&#39;Women medals per edition of the Games&#39;) . Usually I cross-check the data: below I tried to review only the medalists for the 1900 Summer edition to see if the visualization is correct. . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] == 1900].head(10) . Okay, let&#8217;s count the rows (same code as above adding the count() function and filtering only for ID) . womenInOlympics[&#39;ID&#39;].loc[womenInOlympics[&#39;Year&#39;] == 1900].count() . So we have 33 records (with repetitions, for example &#8216;Marion Jones (-Farquhar)&#8217; won a medal both for Tennis Women&#8217;s Singles and Tennis Mixed Doubles &#8211; To be sure I cross-checked also with Wikipedia and the outcome seems correct). . Medals per country . Let&#8217;s now review the top 5 gold medal countries: . goldMedals.region.value_counts().reset_index(name=&#39;Medal&#39;).head() . Let&#8217;s plot this: . totalGoldMedals = goldMedals.region.value_counts().reset_index(name=&#39;Medal&#39;).head(5) g = sns.catplot(x=&quot;index&quot;, y=&quot;Medal&quot;, data=totalGoldMedals, height=6, kind=&quot;bar&quot;, palette=&quot;muted&quot;) g.despine(left=True) g.set_xlabels(&quot;Top 5 countries&quot;) g.set_ylabels(&quot;Number of Medals&quot;) plt.title(&#39;Medals per Country&#39;) . The USA seems to be the most winning country. . But which are the most awarded disciplines of American Athletes? . Disciplines with the greatest number of Gold Medals . Let&#8217;s create a dataframe to filter the gold medals only for the USA. . goldMedalsUSA = goldMedals.loc[goldMedals[&#39;NOC&#39;] == &#39;USA&#39;] . Done! Now, we can count the medals per discipline . goldMedalsUSA.Event.value_counts().reset_index(name=&#39;Medal&#39;).head(20) . Let&#8217;s slice the dataframe using only the data of male athletes to better review it: . basketballGoldUSA = goldMedalsUSA.loc[(goldMedalsUSA[&#39;Sport&#39;] == &#39;Basketball&#39;) &amp; (goldMedalsUSA[&#39;Sex&#39;] == &#39;M&#39;)].sort_values([&#39;Year&#39;]) basketballGoldUSA.head(15) . What we supposed is true: the medals are not grouped by Edition/Team but we were counting the gold medals of each member of the team! . Let&#8217;s proceed grouping by year the athletes &#8211; the idea is to create a new dataframe to make a pre-filter using only the first record for each member of the team. . groupedBasketUSA = basketballGoldUSA.groupby([&#39;Year&#39;]).first() groupedBasketUSA groupedBasketUSA[&#39;ID&#39;].count() . What is the median height/weight of an Olympic medalist? . Let&#8217;s try to plot a scatterplot of height vs weight to see the distribution of values (without grouping by discipline). . First of all, we have to take again the goldMedals dataframe . goldMedals.head() . We can see that we have NaN values both in height and weight columns . At this point, we can act as follows: . Using only the rows that has a value in the Height and Weight columns; | Replace the value with the mean of the column. | Solution 2 in my opinion it is not the best way to go: we are talking about data of athletes of different ages and different disciplines (that have done different training). . Let&#8217;s go with solution 1. . The first thing to do is to collect general information about the dataframe that we have to use: goldMedals. . goldMedals.info() . Okay, we have more than 13.000 rows. . We will now create a dataframe filtering only the rows that has the column Height and Weight populated. . notNullMedals = goldMedals[(goldMedals[&#39;Height&#39;].notnull()) &amp; (goldMedals[&#39;Weight&#39;].notnull())] . plt.figure(figsize=(12, 10)) ax = sns.scatterplot(x=&quot;Height&quot;, y=&quot;Weight&quot;, data=notNullMedals) plt.title(&#39;Height vs Weight of Olympic Medalists&#39;) . The vast majority of the samples show a linear relation between height and weight (the more the weight, the more the height). . We have exceptions and I am willing to know more! . For example, let&#8217;s see which is the athlete that weighs more than 160 kilograms. . notNullMedals.loc[notNullMedals[&#39;Weight&#39;] &gt; 160] . MenOverTime = merged[(merged.Sex == &#39;M&#39;) &amp; (merged.Season == &#39;Summer&#39;)] WomenOverTime = merged[(merged.Sex == &#39;F&#39;) &amp; (merged.Season == &#39;Summer&#39;)] . MenOverTime.head() . part = MenOverTime.groupby(&#39;Year&#39;)[&#39;Sex&#39;].value_counts() plt.figure(figsize=(20, 10)) part.loc[:,&#39;M&#39;].plot() plt.title(&#39;Variation of Male Athletes over time&#39;) . part = WomenOverTime.groupby(&#39;Year&#39;)[&#39;Sex&#39;].value_counts() plt.figure(figsize=(20, 10)) part.loc[:,&#39;F&#39;].plot() plt.title(&#39;Variation of Female Athletes over time&#39;) . What I immediately saw is that for women: . We have a steep increase in the population; | The grow is constant. | On the other hand, the grow for men seems less strong: . After the 1990 we can see a relevant decrease in the number of male athletes at the summer games; | The growth has slowly restarted recently. | plt.figure(figsize=(20, 10)) sns.boxplot(&#39;Year&#39;, &#39;Age&#39;, data=MenOverTime) plt.title(&#39;Variation of Age for Male Athletes over time&#39;) . What is strange for me is the age of some athletes in the games between the 1924 and the 1948: let&#8217;s check all the people with age greater than 80. . MenOverTime.loc[MenOverTime[&#39;Age&#39;] &gt; 80].head(10) . plt.figure(figsize=(20, 10)) sns.boxplot(&#39;Year&#39;, &#39;Age&#39;, data=WomenOverTime) plt.title(&#39;Variation of Age for Female Athletes over time&#39;) . Interesting points for me: . Generally, the age distribution starts has a lower minimum and a lower maximum; | In 1904 the age distribution is strongly different from the other Olympics: let’s know more about this point: | . WomenOverTime.loc[WomenOverTime[&#39;Year&#39;] == 1904] . We will now try using a pointplot to visualize the variation in weight over athletes. . The first graph will show data for men, the second for women: . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=MenOverTime) plt.title(&#39;Variation of Weight for Male Athletes over time&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=WomenOverTime) plt.title(&#39;Variation of Weight for Female Athletes over time&#39;) . What we can see is that it seems that we do not have data for women before 1924. Let&#8217;s try filtering all the women athletes for that period to review this point: . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] &lt; 1924].head(20) . Using the same pointplot (with a different palette) we can plot the weight change along time. . The first graph will show the information for men, the second for women: . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] &lt; 1924].head(20) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=WomenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Height for Female Athletes over time&#39;) . What we may see: . For both men and women, the height is incrementing over time but it is decreasing between the 2012 and the 2016. | For women we have a peak between 1928 and 1948, let’s deepen this point: | . WomenOverTime.loc[(WomenOverTime[&#39;Year&#39;] &gt; 1924) &amp; (WomenOverTime[&#39;Year&#39;] &lt; 1952)].head(10) . MenOverTime.head() . itMenOverTime = MenOverTime.loc[MenOverTime[&#39;region&#39;] == &#39;Italy&#39;] . sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=itMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Age for Italian Male Athletes over time&#39;) . now we can plot the change over time: . itWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;region&#39;] == &#39;Italy&#39;] sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=itWomenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Age for Italian Female Athletes over time&#39;) . Let&#8217;s first of all isolate all the discipline of the Olympics dataframe. . My idea is to see if Gymnastics is called differently or if there is any type. . MenOverTime[&#39;Sport&#39;].unique().tolist() . Okay, the string to use to filter is &#8216;Gymnastics&#8217;: let&#8217;s create two new dataframes for men and women. . gymMenOverTime = MenOverTime.loc[MenOverTime[&#39;Sport&#39;] == &#39;Gymnastics&#39;] gymWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;Sport&#39;] == &#39;Gymnastics&#39;] . Okay: let&#8217;s now create our plot for male and female athletes and then we can make our observations . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Weight&#39;, data=gymMenOverTime) plt.title(&#39;Weight over year for Male Gymnasts&#39;) . A few things I noticed: . The weight for female Gymnasts has go down for 60 to 50 kilograms on average; | The weight for men has been more or less stable since 1964; | The height is more stable for both men and women. ### Also, men weight data from 1924 seems missing: let’s check. | plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Height&#39;, data=gymMenOverTime) plt.title(&#39;Height over year for Male Gymnasts&#39;) . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Weight&#39;, data=gymWomenOverTime) plt.title(&#39;Weight over year for Female Gymnasts&#39;) . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Height&#39;, data=gymWomenOverTime) plt.title(&#39;Height over year for Female Gymnasts&#39;) . gymMenOverTime[&#39;Weight&#39;].loc[gymMenOverTime[&#39;Year&#39;] == 1924].isnull().all() . Weightlifting . Let&#8217;s work on an analysis similar to what we have done for Gymnastics also for the Lifters. . We can start creating a new, dedicated dataframe . wlMenOverTime = MenOverTime.loc[MenOverTime[&#39;Sport&#39;] == &#39;Weightlifting&#39;] wlWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;Sport&#39;] == &#39;Weightlifting&#39;] . Okay: let&#8217;s now create our plot for male and female athletes and then we can make our observations . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=wlMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Weight over year for Male Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=wlMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Height over year for Male Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=wlWomenOverTime) plt.title(&#39;Weight over year for Female Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=wlWomenOverTime) plt.title(&#39;Height over year for Female Lifters&#39;) .",
            "url": "https://sakibb019.github.io/Portfolio/2021/07/25/olympic_games_analysis_using_python.html",
            "relUrl": "/2021/07/25/olympic_games_analysis_using_python.html",
            "date": " • Jul 25, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Amazon-Bestselling-Books-Analysis-with-Python-language",
            "content": "import pandas as pd # dataframe manipulation import numpy as np # linear algebra import os for dirname, _, filenames in os.walk(&#39;/books/&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . books=pd.read_csv(&#39;AmazonBooks - Sheet1.csv&#39;) . books.head() . Name Author User Rating Reviews Price Year Genre . 0 10-Day Green Smoothie Cleanse | JJ Smith | 4.7 | 17350 | 8 | 2016 | Non Fiction | . 1 11/22/63: A Novel | Stephen King | 4.6 | 2052 | 22 | 2011 | Fiction | . 2 12 Rules for Life: An Antidote to Chaos | Jordan B. Peterson | 4.7 | 18979 | 15 | 2018 | Non Fiction | . 3 1984 (Signet Classics) | George Orwell | 4.7 | 21424 | 6 | 2017 | Fiction | . 4 5,000 Awesome Facts (About Everything!) (Natio... | National Geographic Kids | 4.8 | 7665 | 12 | 2019 | Non Fiction | . books.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 600 entries, 0 to 599 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 Name 600 non-null object 1 Author 600 non-null object 2 User Rating 600 non-null float64 3 Reviews 600 non-null int64 4 Price 600 non-null int64 5 Year 600 non-null int64 6 Genre 600 non-null object dtypes: float64(1), int64(3), object(3) memory usage: 32.9+ KB . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 40 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2017 | Fiction | . 41 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2019 | Fiction | . 81 Dog Man and Cat Kid: From the Creator of Capta... | Dav Pilkey | 4.9 | 5062 | 6 | 2018 | Fiction | . 82 Dog Man: A Tale of Two Kitties: From the Creat... | Dav Pilkey | 4.9 | 4786 | 8 | 2017 | Fiction | . 83 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2018 | Fiction | . ... ... | ... | ... | ... | ... | ... | ... | . 573 The Deep End (Diary of a Wimpy Kid Book 15) | Jeff Kinney | 4.9 | 26047 | 7 | 2020 | Fiction | . 575 I Love You to the Moon and Back | Amelia Hepworth | 4.9 | 24356 | 1 | 2020 | Fiction | . 580 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 25321 | 5 | 2020 | Fiction | . 582 Magnolia Table, Volume 2 | Joanna Gaines | 4.9 | 16515 | 17 | 2020 | Non Fiction | . 594 Chicka Chicka Boom Boom | Bill Martin Jr. | 4.9 | 20705 | 4 | 2020 | Fiction | . 61 rows × 7 columns . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()].count() . Name 61 Author 61 User Rating 61 Reviews 61 Price 61 Year 61 Genre 61 dtype: int64 . import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline . plt.figure(figsize=(12,4)) sns.barplot(x=&#39;Year&#39;,y=&#39;User Rating&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ceceabd0&gt; . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].min()] . Name Author User Rating Reviews Price Year Genre . 353 The Casual Vacancy | J.K. Rowling | 3.3 | 9372 | 12 | 2012 | Fiction | . books.groupby(&#39;Year&#39;)[&#39;User Rating&#39;].max() . Year 2009 4.8 2010 4.8 2011 4.9 2012 4.9 2013 4.9 2014 4.9 2015 4.9 2016 4.9 2017 4.9 2018 4.9 2019 4.9 2020 4.9 Name: User Rating, dtype: float64 . books[books[&#39;Reviews&#39;]==books[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 552 Where the Crawdads Sing | Delia Owens | 4.8 | 120727 | 9 | 2020 | Fiction | . books[books[&#39;Reviews&#39;]==books[&#39;Reviews&#39;].min()] . Name Author User Rating Reviews Price Year Genre . 78 Divine Soul Mind Body Healing and Transmission... | Zhi Gang Sha | 4.6 | 37 | 6 | 2009 | Non Fiction | . books.groupby(&#39;Year&#39;)[&#39;Reviews&#39;].max() . Year 2009 19720 2010 32122 2011 32122 2012 57271 2013 57271 2014 57271 2015 79446 2016 79446 2017 29442 2018 61133 2019 87841 2020 120727 Name: Reviews, dtype: int64 . sns.histplot(x=&#39;Reviews&#39;,data=books,hue=&#39;Genre&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce290f50&gt; . sns.displot(x=books[&#39;User Rating&#39;],kde=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87ceab3ad0&gt; . sns.boxplot(x=&#39;Year&#39;,y=&#39;User Rating&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce7acc90&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;User Rating&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce997cd0&gt; . sns.lineplot(x=&quot;Year&quot;, y=&quot;User Rating&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce505750&gt; . books[books[&#39;Price&#39;]==books[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 69 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2013 | Non Fiction | . 70 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2014 | Non Fiction | . sns.histplot(x=&#39;Price&#39;,data=books,kde=True,color=&#39;blue&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce86a510&gt; . sns.displot(x=books[&#39;Price&#39;], hue=books[&#39;Genre&#39;], kind=&quot;kde&quot;, fill=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87cde27710&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;Price&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce33b1d0&gt; . sns.countplot(x=&#39;Genre&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce8d8810&gt; . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;Price&#39;]==df[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 473 The Twilight Saga Collection | Stephenie Meyer | 4.7 | 3801 | 82 | 2009 | Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;Price&#39;]==df[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 69 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2013 | Non Fiction | . 70 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2014 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;User Rating&#39;]==df[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 40 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2017 | Fiction | . 41 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2019 | Fiction | . 81 Dog Man and Cat Kid: From the Creator of Capta... | Dav Pilkey | 4.9 | 5062 | 6 | 2018 | Fiction | . 82 Dog Man: A Tale of Two Kitties: From the Creat... | Dav Pilkey | 4.9 | 4786 | 8 | 2017 | Fiction | . 83 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2018 | Fiction | . 84 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2019 | Fiction | . 85 Dog Man: Fetch-22: From the Creator of Captain... | Dav Pilkey | 4.9 | 12619 | 8 | 2019 | Fiction | . 86 Dog Man: For Whom the Ball Rolls: From the Cre... | Dav Pilkey | 4.9 | 9089 | 8 | 2019 | Fiction | . 87 Dog Man: Lord of the Fleas: From the Creator o... | Dav Pilkey | 4.9 | 5470 | 6 | 2018 | Fiction | . 146 Goodnight, Goodnight Construction Site (Hardco... | Sherri Duskey Rinker | 4.9 | 7038 | 7 | 2012 | Fiction | . 147 Goodnight, Goodnight Construction Site (Hardco... | Sherri Duskey Rinker | 4.9 | 7038 | 7 | 2013 | Fiction | . 153 Harry Potter and the Chamber of Secrets: The I... | J.K. Rowling | 4.9 | 19622 | 30 | 2016 | Fiction | . 155 Harry Potter and the Goblet of Fire: The Illus... | J. K. Rowling | 4.9 | 7758 | 18 | 2019 | Fiction | . 156 Harry Potter and the Prisoner of Azkaban: The ... | J.K. Rowling | 4.9 | 3146 | 30 | 2017 | Fiction | . 157 Harry Potter and the Sorcerer&#39;s Stone: The Ill... | J.K. Rowling | 4.9 | 10052 | 22 | 2016 | Fiction | . 207 Last Week Tonight with John Oliver Presents A ... | Jill Twiss | 4.9 | 11881 | 13 | 2018 | Fiction | . 219 Little Blue Truck | Alice Schertle | 4.9 | 1884 | 0 | 2014 | Fiction | . 245 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2012 | Fiction | . 246 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2013 | Fiction | . 247 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2014 | Fiction | . 248 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2015 | Fiction | . 249 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2016 | Fiction | . 250 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2017 | Fiction | . 251 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2018 | Fiction | . 252 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2019 | Fiction | . 288 Rush Revere and the Brave Pilgrims: Time-Trave... | Rush Limbaugh | 4.9 | 7150 | 12 | 2013 | Fiction | . 289 Rush Revere and the First Patriots: Time-Trave... | Rush Limbaugh | 4.9 | 3836 | 12 | 2014 | Fiction | . 303 Strange Planet (Strange Planet Series) | Nathan W. Pyle | 4.9 | 9382 | 6 | 2019 | Fiction | . 420 The Legend of Zelda: Hyrule Historia | Patrick Thorpe | 4.9 | 5396 | 20 | 2013 | Fiction | . 476 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2013 | Fiction | . 477 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2014 | Fiction | . 478 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2015 | Fiction | . 479 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2016 | Fiction | . 480 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2017 | Fiction | . 481 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2018 | Fiction | . 482 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2019 | Fiction | . 486 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2016 | Fiction | . 487 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2017 | Fiction | . 488 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2018 | Fiction | . 489 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2019 | Fiction | . 545 Wrecking Ball (Diary of a Wimpy Kid Book 14) | Jeff Kinney | 4.9 | 9413 | 8 | 2019 | Fiction | . 561 Dog Man: Grime and Punishment | Dav Pilkey | 4.9 | 31045 | 6 | 2020 | Fiction | . 573 The Deep End (Diary of a Wimpy Kid Book 15) | Jeff Kinney | 4.9 | 26047 | 7 | 2020 | Fiction | . 575 I Love You to the Moon and Back | Amelia Hepworth | 4.9 | 24356 | 1 | 2020 | Fiction | . 580 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 25321 | 5 | 2020 | Fiction | . 594 Chicka Chicka Boom Boom | Bill Martin Jr. | 4.9 | 20705 | 4 | 2020 | Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;User Rating&#39;]==df[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 151 Hamilton: The Revolution | Lin-Manuel Miranda | 4.9 | 5867 | 54 | 2016 | Non Fiction | . 174 Humans of New York : Stories | Brandon Stanton | 4.9 | 2812 | 17 | 2015 | Non Fiction | . 187 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2011 | Non Fiction | . 188 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2012 | Non Fiction | . 189 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2013 | Non Fiction | . 190 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2014 | Non Fiction | . 191 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2015 | Non Fiction | . 192 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2016 | Non Fiction | . 244 Obama: An Intimate Portrait | Pete Souza | 4.9 | 3192 | 22 | 2017 | Non Fiction | . 431 The Magnolia Story | Chip Gaines | 4.9 | 7861 | 5 | 2016 | Non Fiction | . 521 Unfreedom of the Press | Mark R. Levin | 4.9 | 5956 | 11 | 2019 | Non Fiction | . 550 A Promised Land | Barack Obama | 4.9 | 83212 | 23 | 2020 | Non Fiction | . 562 The Very Hungry Caterpillar | Eric Carle | 4.9 | 35965 | 7 | 2020 | Non Fiction | . 571 The Boy, the Mole, the Fox and the Horse | Charlie Mackesy | 4.9 | 53549 | 15 | 2020 | Non Fiction | . 582 Magnolia Table, Volume 2 | Joanna Gaines | 4.9 | 16515 | 17 | 2020 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;Reviews&#39;]==df[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 563 Becoming | Michelle Obama | 4.8 | 99498 | 10 | 2020 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;Reviews&#39;]==df[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 552 Where the Crawdads Sing | Delia Owens | 4.8 | 120727 | 9 | 2020 | Fiction | . sns.displot(x=books[&#39;Reviews&#39;], hue=books[&#39;Genre&#39;], kind=&quot;kde&quot;,fill=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87cea73cd0&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;Reviews&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce6d8fd0&gt; . books[&#39;Author&#39;].value_counts() . Jeff Kinney 13 Gary Chapman 12 Suzanne Collins 12 Rick Riordan 11 American Psychological Association 10 .. Christopher Paolini 1 Jon Stewart 1 Bill Martin Jr. 1 Don Miguel Ruiz 1 Ian K. Smith M.D. 1 Name: Author, Length: 275, dtype: int64 . df=books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()] df[&#39;Author&#39;].unique() . array([&#39;Bill Martin Jr.&#39;, &#39;Dav Pilkey&#39;, &#39;Sherri Duskey Rinker&#39;, &#39;Lin-Manuel Miranda&#39;, &#39;J.K. Rowling&#39;, &#39;J. K. Rowling&#39;, &#39;Brandon Stanton&#39;, &#39;Sarah Young&#39;, &#39;Jill Twiss&#39;, &#39;Alice Schertle&#39;, &#39;Pete Souza&#39;, &#39;Dr. Seuss&#39;, &#39;Rush Limbaugh&#39;, &#39;Nathan W. Pyle&#39;, &#39;Patrick Thorpe&#39;, &#39;Chip Gaines&#39;, &#39;Eric Carle&#39;, &#39;Emily Winfield Martin&#39;, &#39;Mark R. Levin&#39;, &#39;Jeff Kinney&#39;, &#39;Barack Obama&#39;, &#39;Charlie Mackesy&#39;, &#39;Amelia Hepworth&#39;, &#39; Bill Martin Jr.&#39;, &#39;Joanna Gaines&#39;], dtype=object) . sns.stripplot(x=&quot;Genre&quot;, y=&quot;User Rating&quot;, data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce3b5210&gt; . sns.heatmap(books.corr(),annot=True,cmap=&#39;magma&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce2ff350&gt; . sns.clustermap(books.corr(),annot=True,cmap=&#39;magma&#39;) . &lt;seaborn.matrix.ClusterGrid at 0x7f87ce4472d0&gt; . sns.pairplot(books) . &lt;seaborn.axisgrid.PairGrid at 0x7f87cdf55590&gt; . books.head() . Name Author User Rating Reviews Price Year Genre . 0 10-Day Green Smoothie Cleanse | JJ Smith | 4.7 | 17350 | 8 | 2016 | Non Fiction | . 1 11/22/63: A Novel | Stephen King | 4.6 | 2052 | 22 | 2011 | Fiction | . 2 12 Rules for Life: An Antidote to Chaos | Jordan B. Peterson | 4.7 | 18979 | 15 | 2018 | Non Fiction | . 3 1984 (Signet Classics) | George Orwell | 4.7 | 21424 | 6 | 2017 | Fiction | . 4 5,000 Awesome Facts (About Everything!) (Natio... | National Geographic Kids | 4.8 | 7665 | 12 | 2019 | Non Fiction | . sns.lmplot(x=&#39;Price&#39;,y=&#39;Year&#39;,data=books,hue=&#39;Genre&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87bde172d0&gt; .",
            "url": "https://sakibb019.github.io/Portfolio/2021/07/24/Amazon-Bestselling-Books-Analysis-with-Python-language.html",
            "relUrl": "/2021/07/24/Amazon-Bestselling-Books-Analysis-with-Python-language.html",
            "date": " • Jul 24, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sakibb019.github.io/Portfolio/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sakibb019.github.io/Portfolio/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sakibb019.github.io/Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sakibb019.github.io/Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}