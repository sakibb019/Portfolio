{
  
    
        "post0": {
            "title": "Title",
            "content": "import tensorflow as tf from tensorflow import keras fashion_mnist = keras.datasets.fashion_mnist (X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data() . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 1s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 8192/5148 [===============================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step . X_train_full.shape . (60000, 28, 28) . X_train_full.dtype . dtype(&#39;uint8&#39;) . X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255. y_valid, y_train = y_train_full[:5000], y_train_full[5000:] X_test = X_test / 255. . plt.imshow(X_train[0], cmap=&quot;binary&quot;) plt.axis(&#39;off&#39;) plt.show() . y_train . array([4, 0, 7, ..., 3, 0, 5], dtype=uint8) . class_names = [&quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;] . class_names[y_train[0]] . &#39;Coat&#39; . X_valid.shape . (5000, 28, 28) . X_valid.shape . (5000, 28, 28) . n_rows = 4 n_cols = 10 plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2)) for row in range(n_rows): for col in range(n_cols): index = n_cols * row + col plt.subplot(n_rows, n_cols, index + 1) plt.imshow(X_train[index], cmap=&quot;binary&quot;, interpolation=&quot;nearest&quot;) plt.axis(&#39;off&#39;) plt.title(class_names[y_train[index]], fontsize=12) plt.subplots_adjust(wspace=0.2, hspace=0.5) save_fig(&#39;fashion_mnist_plot&#39;, tight_layout=False) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-23-5f1e97bb1426&gt; in &lt;module&gt; 10 plt.title(class_names[y_train[index]], fontsize=12) 11 plt.subplots_adjust(wspace=0.2, hspace=0.5) &gt; 12 save_fig(&#39;fashion_mnist_plot&#39;, tight_layout=False) 13 plt.show() NameError: name &#39;save_fig&#39; is not defined . model = keras.models.Sequential() model.add(keras.layers.Flatten(input_shape=[28, 28])) model.add(keras.layers.Dense(300, activation=&quot;relu&quot;)) model.add(keras.layers.Dense(100, activation=&quot;relu&quot;)) model.add(keras.layers.Dense(10, activation=&quot;softmax&quot;)) keras.backend.clear_session() np.random.seed(42) tf.random.set_seed(42) . AttributeError Traceback (most recent call last) &lt;ipython-input-25-e54bf78ebc8b&gt; in &lt;module&gt; 6 keras.backend.clear_session() 7 np.random.seed(42) -&gt; 8 tf.random.set_seed(42) AttributeError: module &#39;tensorflow._api.v1.random&#39; has no attribute &#39;set_seed&#39; . model = keras.models.Sequential([ keras.layers.Flatten(input_shape=[28, 28]), keras.layers.Dense(300, activation=&quot;relu&quot;), keras.layers.Dense(100, activation=&quot;relu&quot;), keras.layers.Dense(10, activation=&quot;softmax&quot;) ]) model.layers . [&lt;tensorflow.python.keras.layers.core.Flatten at 0x7f5f5df7b610&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5df7b590&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5df7b710&gt;, &lt;tensorflow.python.keras.layers.core.Dense at 0x7f5f5e190750&gt;] . model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 _________________________________________________________________ dense (Dense) (None, 300) 235500 _________________________________________________________________ dense_1 (Dense) (None, 100) 30100 _________________________________________________________________ dense_2 (Dense) (None, 10) 1010 ================================================================= Total params: 266,610 Trainable params: 266,610 Non-trainable params: 0 _________________________________________________________________ . hidden1 = model.layers[1] hidden1.name . &#39;dense&#39; . model.get_layer(hidden1.name) is hidden1 . True . weights, biases = hidden1.get_weights() . biases . array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32) . model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=&quot;sgd&quot;, metrics=[&quot;accuracy&quot;]) . history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid)) . Train on 55000 samples, validate on 5000 samples Epoch 1/30 55000/55000 [==============================] - 22s 399us/sample - loss: 0.7050 - acc: 0.7663 - val_loss: 0.4985 - val_acc: 0.8366 Epoch 2/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.4845 - acc: 0.8310 - val_loss: 0.4563 - val_acc: 0.8426 Epoch 3/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.4408 - acc: 0.8468 - val_loss: 0.4093 - val_acc: 0.8610 Epoch 4/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.4148 - acc: 0.8551 - val_loss: 0.4008 - val_acc: 0.8656 Epoch 5/30 55000/55000 [==============================] - 21s 384us/sample - loss: 0.3948 - acc: 0.8615 - val_loss: 0.3795 - val_acc: 0.8696 Epoch 6/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3792 - acc: 0.8668 - val_loss: 0.3749 - val_acc: 0.8722 Epoch 7/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3649 - acc: 0.8714 - val_loss: 0.3761 - val_acc: 0.8710 Epoch 8/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3537 - acc: 0.8757 - val_loss: 0.3781 - val_acc: 0.8688 Epoch 9/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3428 - acc: 0.8790 - val_loss: 0.3459 - val_acc: 0.8806 Epoch 10/30 55000/55000 [==============================] - 21s 383us/sample - loss: 0.3341 - acc: 0.8824 - val_loss: 0.3710 - val_acc: 0.8702 Epoch 11/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3260 - acc: 0.8839 - val_loss: 0.3332 - val_acc: 0.8834 Epoch 12/30 55000/55000 [==============================] - 21s 389us/sample - loss: 0.3173 - acc: 0.8873 - val_loss: 0.3409 - val_acc: 0.8792 Epoch 13/30 55000/55000 [==============================] - 22s 393us/sample - loss: 0.3092 - acc: 0.8901 - val_loss: 0.3482 - val_acc: 0.8780 Epoch 14/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.3039 - acc: 0.8902 - val_loss: 0.3219 - val_acc: 0.8864 Epoch 15/30 55000/55000 [==============================] - 21s 384us/sample - loss: 0.2959 - acc: 0.8939 - val_loss: 0.3214 - val_acc: 0.8852 Epoch 16/30 55000/55000 [==============================] - 21s 381us/sample - loss: 0.2903 - acc: 0.8957 - val_loss: 0.3333 - val_acc: 0.8830 Epoch 17/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.2847 - acc: 0.8980 - val_loss: 0.3232 - val_acc: 0.8824 Epoch 18/30 55000/55000 [==============================] - 21s 389us/sample - loss: 0.2802 - acc: 0.8997 - val_loss: 0.3286 - val_acc: 0.8780 Epoch 19/30 55000/55000 [==============================] - 21s 387us/sample - loss: 0.2740 - acc: 0.9018 - val_loss: 0.3057 - val_acc: 0.8892 Epoch 20/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2692 - acc: 0.9037 - val_loss: 0.3078 - val_acc: 0.8890 Epoch 21/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2652 - acc: 0.9053 - val_loss: 0.3153 - val_acc: 0.8864 Epoch 22/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2588 - acc: 0.9077 - val_loss: 0.3196 - val_acc: 0.8846 Epoch 23/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2556 - acc: 0.9078 - val_loss: 0.3162 - val_acc: 0.8868 Epoch 24/30 55000/55000 [==============================] - 21s 385us/sample - loss: 0.2507 - acc: 0.9101 - val_loss: 0.3081 - val_acc: 0.8880 Epoch 25/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2462 - acc: 0.9126 - val_loss: 0.3017 - val_acc: 0.8894 Epoch 26/30 55000/55000 [==============================] - 21s 380us/sample - loss: 0.2424 - acc: 0.9133 - val_loss: 0.3277 - val_acc: 0.8830 Epoch 27/30 55000/55000 [==============================] - 21s 382us/sample - loss: 0.2395 - acc: 0.9148 - val_loss: 0.3006 - val_acc: 0.8904 Epoch 28/30 55000/55000 [==============================] - 21s 378us/sample - loss: 0.2348 - acc: 0.9160 - val_loss: 0.3030 - val_acc: 0.8914 Epoch 29/30 55000/55000 [==============================] - 20s 372us/sample - loss: 0.2306 - acc: 0.9178 - val_loss: 0.2998 - val_acc: 0.8918 Epoch 30/30 55000/55000 [==============================] - 21s 373us/sample - loss: 0.2273 - acc: 0.9189 - val_loss: 0.3016 - val_acc: 0.8948 . import pandas as pd pd.DataFrame(history.history).plot(figsize=(8, 5)) plt.grid(True) plt.gca().set_ylim(0, 1) save_fig(&quot;keras_learning_curves_plot&quot;) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-35-e5ab1d7e7f53&gt; in &lt;module&gt; 4 plt.grid(True) 5 plt.gca().set_ylim(0, 1) -&gt; 6 save_fig(&#34;keras_learning_curves_plot&#34;) 7 plt.show() NameError: name &#39;save_fig&#39; is not defined . model.evaluate(X_test, y_test) . 10000/10000 [==============================] - 1s 128us/sample - loss: 0.3316 - acc: 0.8852 . [0.3315748940348625, 0.8852] . X_new = X_test[:3] y_proba = model.predict(X_new) y_proba.round(2) . array([[0. , 0. , 0. , 0. , 0. , 0.01, 0. , 0.03, 0. , 0.97], [0. , 0. , 0.98, 0. , 0.02, 0. , 0. , 0. , 0. , 0. ], [0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32) . y_pred = model.predict_classes(X_new) y_pred . array([9, 2, 1]) . np.array(class_names)[y_pred] . array([&#39;Ankle boot&#39;, &#39;Pullover&#39;, &#39;Trouser&#39;], dtype=&#39;&lt;U11&#39;) . y_new = y_test[:3] plt.figure(figsize=(7.2, 2.4)) for index, image in enumerate(X_new): plt.subplot(1, 3, index + 1) plt.imshow(image, cmap=&quot;binary&quot;, interpolation=&quot;nearest&quot;) plt.axis(&#39;off&#39;) plt.title(class_names[y_test[index]], fontsize=12) plt.subplots_adjust(wspace=0.2, hspace=0.5) save_fig(&#39;fashion_mnist_images_plot&#39;, tight_layout=False) plt.show() . NameError Traceback (most recent call last) &lt;ipython-input-40-dd332162bb4a&gt; in &lt;module&gt; 7 plt.title(class_names[y_test[index]], fontsize=12) 8 plt.subplots_adjust(wspace=0.2, hspace=0.5) -&gt; 9 save_fig(&#39;fashion_mnist_images_plot&#39;, tight_layout=False) 10 plt.show() NameError: name &#39;save_fig&#39; is not defined .",
            "url": "https://sakibb019.github.io/Portfolio/2021/08/06/Image-classifiaction.html",
            "relUrl": "/2021/08/06/Image-classifiaction.html",
            "date": " • Aug 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Explore a dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016",
            "content": ". import numpy as np import pandas as pd import seaborn as sns from matplotlib import pyplot as plt . Collecting information about both the data sets . We are going to: . Review the first lines of the data; | Use the describe and info functions to collect statistical information, datatypes, column names and other information | data = pd.read_csv(&#39;../input/athlete-events/athlete_events.csv&#39;) regions = pd.read_csv(&#39;../input/athlete-events/noc_regions.csv&#39;) . data.describe() . data.info() . regions = pd.read_csv(&#39;../input/athlete-events/noc_regions.csv&#39;) regions.head() . Joining the data frames . merged = pd.merge(data, regions, on=&#39;NOC&#39;, how=&#39;left&#39;) merged.head() . Distribution of the age of gold medalists . Let&#8217;s start creating a new data frame including only gold medalists. . goldMedals = merged[(merged.Medal == &#39;Gold&#39;)] goldMedals.head() . I would like to have a plot of the Age to see the distribution but I need to check first if the Age column contains NaN values. . goldMedals.isnull().any() . Let&#8217;s take only the values that are different from NaN. . goldMedals = goldMedals[np.isfinite(goldMedals[&#39;Age&#39;])] . We can now create a countplot to see the result of our work: . plt.figure(figsize=(20, 10)) plt.tight_layout() sns.countplot(goldMedals[&#39;Age&#39;]) plt.title(&#39;Distribution of Gold Medals&#39;) . It seems that we have people with Age greater that 50 with a gold medal: Let&#8217;s know more about those people. . goldMedals[&#39;ID&#39;][goldMedals[&#39;Age&#39;] &gt; 50].count() . 65 people. Wonderul But which disciplines allows you to land a gold medal after your fifties? . We will now create a new dataframe called masterDisciplines in which we will insert this new set of people and then create a visualization with it. . masterDisciplines = goldMedals[&#39;Sport&#39;][goldMedals[&#39;Age&#39;] &gt; 50] plt.figure(figsize=(20, 10)) plt.tight_layout() sns.countplot(masterDisciplines) plt.title(&#39;Gold Medals for Athletes Over 50&#39;) . It seems that our senior gold medalists are shooters, archers, sailors and, above all, horse riders! . It makes sense: I cannot imagine a sprinter making 100 meters in 10 seconds at 55, but who knows! . Women in Athletics . Studying the data we can try to understand how much medals we have only for women in the recent history of the Summer Games. Let&#8217;s create a filtered dataset : . womenInOlympics = merged[(merged.Sex == &#39;F&#39;) &amp; (merged.Season == &#39;Summer&#39;)] womenInOlympics.head(10) . To plot the curve over time, let&#8217;s create a plot in which we put the year (on the x-axis) and count of the number of medals per edition of the games (consider that we will have more medals for the same athlete). . sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=womenInOlympics) plt.title(&#39;Women medals per edition of the Games&#39;) . Usually I cross-check the data: below I tried to review only the medalists for the 1900 Summer edition to see if the visualization is correct. . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] == 1900].head(10) . Okay, let&#8217;s count the rows (same code as above adding the count() function and filtering only for ID) . womenInOlympics[&#39;ID&#39;].loc[womenInOlympics[&#39;Year&#39;] == 1900].count() . So we have 33 records (with repetitions, for example &#8216;Marion Jones (-Farquhar)&#8217; won a medal both for Tennis Women&#8217;s Singles and Tennis Mixed Doubles &#8211; To be sure I cross-checked also with Wikipedia and the outcome seems correct). . Medals per country . Let&#8217;s now review the top 5 gold medal countries: . goldMedals.region.value_counts().reset_index(name=&#39;Medal&#39;).head() . Let&#8217;s plot this: . totalGoldMedals = goldMedals.region.value_counts().reset_index(name=&#39;Medal&#39;).head(5) g = sns.catplot(x=&quot;index&quot;, y=&quot;Medal&quot;, data=totalGoldMedals, height=6, kind=&quot;bar&quot;, palette=&quot;muted&quot;) g.despine(left=True) g.set_xlabels(&quot;Top 5 countries&quot;) g.set_ylabels(&quot;Number of Medals&quot;) plt.title(&#39;Medals per Country&#39;) . The USA seems to be the most winning country. . But which are the most awarded disciplines of American Athletes? . Disciplines with the greatest number of Gold Medals . Let&#8217;s create a dataframe to filter the gold medals only for the USA. . goldMedalsUSA = goldMedals.loc[goldMedals[&#39;NOC&#39;] == &#39;USA&#39;] . Done! Now, we can count the medals per discipline . goldMedalsUSA.Event.value_counts().reset_index(name=&#39;Medal&#39;).head(20) . Let&#8217;s slice the dataframe using only the data of male athletes to better review it: . basketballGoldUSA = goldMedalsUSA.loc[(goldMedalsUSA[&#39;Sport&#39;] == &#39;Basketball&#39;) &amp; (goldMedalsUSA[&#39;Sex&#39;] == &#39;M&#39;)].sort_values([&#39;Year&#39;]) basketballGoldUSA.head(15) . What we supposed is true: the medals are not grouped by Edition/Team but we were counting the gold medals of each member of the team! . Let&#8217;s proceed grouping by year the athletes &#8211; the idea is to create a new dataframe to make a pre-filter using only the first record for each member of the team. . groupedBasketUSA = basketballGoldUSA.groupby([&#39;Year&#39;]).first() groupedBasketUSA groupedBasketUSA[&#39;ID&#39;].count() . What is the median height/weight of an Olympic medalist? . Let&#8217;s try to plot a scatterplot of height vs weight to see the distribution of values (without grouping by discipline). . First of all, we have to take again the goldMedals dataframe . goldMedals.head() . We can see that we have NaN values both in height and weight columns . At this point, we can act as follows: . Using only the rows that has a value in the Height and Weight columns; | Replace the value with the mean of the column. | Solution 2 in my opinion it is not the best way to go: we are talking about data of athletes of different ages and different disciplines (that have done different training). . Let&#8217;s go with solution 1. . The first thing to do is to collect general information about the dataframe that we have to use: goldMedals. . goldMedals.info() . Okay, we have more than 13.000 rows. . We will now create a dataframe filtering only the rows that has the column Height and Weight populated. . notNullMedals = goldMedals[(goldMedals[&#39;Height&#39;].notnull()) &amp; (goldMedals[&#39;Weight&#39;].notnull())] . plt.figure(figsize=(12, 10)) ax = sns.scatterplot(x=&quot;Height&quot;, y=&quot;Weight&quot;, data=notNullMedals) plt.title(&#39;Height vs Weight of Olympic Medalists&#39;) . The vast majority of the samples show a linear relation between height and weight (the more the weight, the more the height). . We have exceptions and I am willing to know more! . For example, let&#8217;s see which is the athlete that weighs more than 160 kilograms. . notNullMedals.loc[notNullMedals[&#39;Weight&#39;] &gt; 160] . MenOverTime = merged[(merged.Sex == &#39;M&#39;) &amp; (merged.Season == &#39;Summer&#39;)] WomenOverTime = merged[(merged.Sex == &#39;F&#39;) &amp; (merged.Season == &#39;Summer&#39;)] . MenOverTime.head() . part = MenOverTime.groupby(&#39;Year&#39;)[&#39;Sex&#39;].value_counts() plt.figure(figsize=(20, 10)) part.loc[:,&#39;M&#39;].plot() plt.title(&#39;Variation of Male Athletes over time&#39;) . part = WomenOverTime.groupby(&#39;Year&#39;)[&#39;Sex&#39;].value_counts() plt.figure(figsize=(20, 10)) part.loc[:,&#39;F&#39;].plot() plt.title(&#39;Variation of Female Athletes over time&#39;) . What I immediately saw is that for women: . We have a steep increase in the population; | The grow is constant. | On the other hand, the grow for men seems less strong: . After the 1990 we can see a relevant decrease in the number of male athletes at the summer games; | The growth has slowly restarted recently. | plt.figure(figsize=(20, 10)) sns.boxplot(&#39;Year&#39;, &#39;Age&#39;, data=MenOverTime) plt.title(&#39;Variation of Age for Male Athletes over time&#39;) . What is strange for me is the age of some athletes in the games between the 1924 and the 1948: let&#8217;s check all the people with age greater than 80. . MenOverTime.loc[MenOverTime[&#39;Age&#39;] &gt; 80].head(10) . plt.figure(figsize=(20, 10)) sns.boxplot(&#39;Year&#39;, &#39;Age&#39;, data=WomenOverTime) plt.title(&#39;Variation of Age for Female Athletes over time&#39;) . Interesting points for me: . Generally, the age distribution starts has a lower minimum and a lower maximum; | In 1904 the age distribution is strongly different from the other Olympics: let’s know more about this point: | . WomenOverTime.loc[WomenOverTime[&#39;Year&#39;] == 1904] . We will now try using a pointplot to visualize the variation in weight over athletes. . The first graph will show data for men, the second for women: . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=MenOverTime) plt.title(&#39;Variation of Weight for Male Athletes over time&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=WomenOverTime) plt.title(&#39;Variation of Weight for Female Athletes over time&#39;) . What we can see is that it seems that we do not have data for women before 1924. Let&#8217;s try filtering all the women athletes for that period to review this point: . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] &lt; 1924].head(20) . Using the same pointplot (with a different palette) we can plot the weight change along time. . The first graph will show the information for men, the second for women: . womenInOlympics.loc[womenInOlympics[&#39;Year&#39;] &lt; 1924].head(20) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=WomenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Height for Female Athletes over time&#39;) . What we may see: . For both men and women, the height is incrementing over time but it is decreasing between the 2012 and the 2016. | For women we have a peak between 1928 and 1948, let’s deepen this point: | . WomenOverTime.loc[(WomenOverTime[&#39;Year&#39;] &gt; 1924) &amp; (WomenOverTime[&#39;Year&#39;] &lt; 1952)].head(10) . MenOverTime.head() . itMenOverTime = MenOverTime.loc[MenOverTime[&#39;region&#39;] == &#39;Italy&#39;] . sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=itMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Age for Italian Male Athletes over time&#39;) . now we can plot the change over time: . itWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;region&#39;] == &#39;Italy&#39;] sns.set(style=&quot;darkgrid&quot;) plt.figure(figsize=(20, 10)) sns.countplot(x=&#39;Year&#39;, data=itWomenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Variation of Age for Italian Female Athletes over time&#39;) . Let&#8217;s first of all isolate all the discipline of the Olympics dataframe. . My idea is to see if Gymnastics is called differently or if there is any type. . MenOverTime[&#39;Sport&#39;].unique().tolist() . Okay, the string to use to filter is &#8216;Gymnastics&#8217;: let&#8217;s create two new dataframes for men and women. . gymMenOverTime = MenOverTime.loc[MenOverTime[&#39;Sport&#39;] == &#39;Gymnastics&#39;] gymWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;Sport&#39;] == &#39;Gymnastics&#39;] . Okay: let&#8217;s now create our plot for male and female athletes and then we can make our observations . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Weight&#39;, data=gymMenOverTime) plt.title(&#39;Weight over year for Male Gymnasts&#39;) . A few things I noticed: . The weight for female Gymnasts has go down for 60 to 50 kilograms on average; | The weight for men has been more or less stable since 1964; | The height is more stable for both men and women. ### Also, men weight data from 1924 seems missing: let’s check. | plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Height&#39;, data=gymMenOverTime) plt.title(&#39;Height over year for Male Gymnasts&#39;) . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Weight&#39;, data=gymWomenOverTime) plt.title(&#39;Weight over year for Female Gymnasts&#39;) . plt.figure(figsize=(20, 10)) sns.barplot(&#39;Year&#39;, &#39;Height&#39;, data=gymWomenOverTime) plt.title(&#39;Height over year for Female Gymnasts&#39;) . gymMenOverTime[&#39;Weight&#39;].loc[gymMenOverTime[&#39;Year&#39;] == 1924].isnull().all() . Weightlifting . Let&#8217;s work on an analysis similar to what we have done for Gymnastics also for the Lifters. . We can start creating a new, dedicated dataframe . wlMenOverTime = MenOverTime.loc[MenOverTime[&#39;Sport&#39;] == &#39;Weightlifting&#39;] wlWomenOverTime = WomenOverTime.loc[WomenOverTime[&#39;Sport&#39;] == &#39;Weightlifting&#39;] . Okay: let&#8217;s now create our plot for male and female athletes and then we can make our observations . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=wlMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Weight over year for Male Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=wlMenOverTime, palette=&#39;Set2&#39;) plt.title(&#39;Height over year for Male Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Weight&#39;, data=wlWomenOverTime) plt.title(&#39;Weight over year for Female Lifters&#39;) . plt.figure(figsize=(20, 10)) sns.pointplot(&#39;Year&#39;, &#39;Height&#39;, data=wlWomenOverTime) plt.title(&#39;Height over year for Female Lifters&#39;) .",
            "url": "https://sakibb019.github.io/Portfolio/2021/07/25/olympic_games_analysis_using_python.html",
            "relUrl": "/2021/07/25/olympic_games_analysis_using_python.html",
            "date": " • Jul 25, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Amazon-Bestselling-Books-Analysis-with-Python-language",
            "content": "import pandas as pd # dataframe manipulation import numpy as np # linear algebra import os for dirname, _, filenames in os.walk(&#39;/books/&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . books=pd.read_csv(&#39;AmazonBooks - Sheet1.csv&#39;) . books.head() . Name Author User Rating Reviews Price Year Genre . 0 10-Day Green Smoothie Cleanse | JJ Smith | 4.7 | 17350 | 8 | 2016 | Non Fiction | . 1 11/22/63: A Novel | Stephen King | 4.6 | 2052 | 22 | 2011 | Fiction | . 2 12 Rules for Life: An Antidote to Chaos | Jordan B. Peterson | 4.7 | 18979 | 15 | 2018 | Non Fiction | . 3 1984 (Signet Classics) | George Orwell | 4.7 | 21424 | 6 | 2017 | Fiction | . 4 5,000 Awesome Facts (About Everything!) (Natio... | National Geographic Kids | 4.8 | 7665 | 12 | 2019 | Non Fiction | . books.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 600 entries, 0 to 599 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 Name 600 non-null object 1 Author 600 non-null object 2 User Rating 600 non-null float64 3 Reviews 600 non-null int64 4 Price 600 non-null int64 5 Year 600 non-null int64 6 Genre 600 non-null object dtypes: float64(1), int64(3), object(3) memory usage: 32.9+ KB . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 40 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2017 | Fiction | . 41 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2019 | Fiction | . 81 Dog Man and Cat Kid: From the Creator of Capta... | Dav Pilkey | 4.9 | 5062 | 6 | 2018 | Fiction | . 82 Dog Man: A Tale of Two Kitties: From the Creat... | Dav Pilkey | 4.9 | 4786 | 8 | 2017 | Fiction | . 83 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2018 | Fiction | . ... ... | ... | ... | ... | ... | ... | ... | . 573 The Deep End (Diary of a Wimpy Kid Book 15) | Jeff Kinney | 4.9 | 26047 | 7 | 2020 | Fiction | . 575 I Love You to the Moon and Back | Amelia Hepworth | 4.9 | 24356 | 1 | 2020 | Fiction | . 580 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 25321 | 5 | 2020 | Fiction | . 582 Magnolia Table, Volume 2 | Joanna Gaines | 4.9 | 16515 | 17 | 2020 | Non Fiction | . 594 Chicka Chicka Boom Boom | Bill Martin Jr. | 4.9 | 20705 | 4 | 2020 | Fiction | . 61 rows × 7 columns . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()].count() . Name 61 Author 61 User Rating 61 Reviews 61 Price 61 Year 61 Genre 61 dtype: int64 . import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline . plt.figure(figsize=(12,4)) sns.barplot(x=&#39;Year&#39;,y=&#39;User Rating&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ceceabd0&gt; . books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].min()] . Name Author User Rating Reviews Price Year Genre . 353 The Casual Vacancy | J.K. Rowling | 3.3 | 9372 | 12 | 2012 | Fiction | . books.groupby(&#39;Year&#39;)[&#39;User Rating&#39;].max() . Year 2009 4.8 2010 4.8 2011 4.9 2012 4.9 2013 4.9 2014 4.9 2015 4.9 2016 4.9 2017 4.9 2018 4.9 2019 4.9 2020 4.9 Name: User Rating, dtype: float64 . books[books[&#39;Reviews&#39;]==books[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 552 Where the Crawdads Sing | Delia Owens | 4.8 | 120727 | 9 | 2020 | Fiction | . books[books[&#39;Reviews&#39;]==books[&#39;Reviews&#39;].min()] . Name Author User Rating Reviews Price Year Genre . 78 Divine Soul Mind Body Healing and Transmission... | Zhi Gang Sha | 4.6 | 37 | 6 | 2009 | Non Fiction | . books.groupby(&#39;Year&#39;)[&#39;Reviews&#39;].max() . Year 2009 19720 2010 32122 2011 32122 2012 57271 2013 57271 2014 57271 2015 79446 2016 79446 2017 29442 2018 61133 2019 87841 2020 120727 Name: Reviews, dtype: int64 . sns.histplot(x=&#39;Reviews&#39;,data=books,hue=&#39;Genre&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce290f50&gt; . sns.displot(x=books[&#39;User Rating&#39;],kde=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87ceab3ad0&gt; . sns.boxplot(x=&#39;Year&#39;,y=&#39;User Rating&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce7acc90&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;User Rating&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce997cd0&gt; . sns.lineplot(x=&quot;Year&quot;, y=&quot;User Rating&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce505750&gt; . books[books[&#39;Price&#39;]==books[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 69 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2013 | Non Fiction | . 70 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2014 | Non Fiction | . sns.histplot(x=&#39;Price&#39;,data=books,kde=True,color=&#39;blue&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce86a510&gt; . sns.displot(x=books[&#39;Price&#39;], hue=books[&#39;Genre&#39;], kind=&quot;kde&quot;, fill=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87cde27710&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;Price&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce33b1d0&gt; . sns.countplot(x=&#39;Genre&#39;,data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce8d8810&gt; . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;Price&#39;]==df[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 473 The Twilight Saga Collection | Stephenie Meyer | 4.7 | 3801 | 82 | 2009 | Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;Price&#39;]==df[&#39;Price&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 69 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2013 | Non Fiction | . 70 Diagnostic and Statistical Manual of Mental Di... | American Psychiatric Association | 4.5 | 6679 | 105 | 2014 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;User Rating&#39;]==df[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 40 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2017 | Fiction | . 41 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 14344 | 5 | 2019 | Fiction | . 81 Dog Man and Cat Kid: From the Creator of Capta... | Dav Pilkey | 4.9 | 5062 | 6 | 2018 | Fiction | . 82 Dog Man: A Tale of Two Kitties: From the Creat... | Dav Pilkey | 4.9 | 4786 | 8 | 2017 | Fiction | . 83 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2018 | Fiction | . 84 Dog Man: Brawl of the Wild: From the Creator o... | Dav Pilkey | 4.9 | 7235 | 4 | 2019 | Fiction | . 85 Dog Man: Fetch-22: From the Creator of Captain... | Dav Pilkey | 4.9 | 12619 | 8 | 2019 | Fiction | . 86 Dog Man: For Whom the Ball Rolls: From the Cre... | Dav Pilkey | 4.9 | 9089 | 8 | 2019 | Fiction | . 87 Dog Man: Lord of the Fleas: From the Creator o... | Dav Pilkey | 4.9 | 5470 | 6 | 2018 | Fiction | . 146 Goodnight, Goodnight Construction Site (Hardco... | Sherri Duskey Rinker | 4.9 | 7038 | 7 | 2012 | Fiction | . 147 Goodnight, Goodnight Construction Site (Hardco... | Sherri Duskey Rinker | 4.9 | 7038 | 7 | 2013 | Fiction | . 153 Harry Potter and the Chamber of Secrets: The I... | J.K. Rowling | 4.9 | 19622 | 30 | 2016 | Fiction | . 155 Harry Potter and the Goblet of Fire: The Illus... | J. K. Rowling | 4.9 | 7758 | 18 | 2019 | Fiction | . 156 Harry Potter and the Prisoner of Azkaban: The ... | J.K. Rowling | 4.9 | 3146 | 30 | 2017 | Fiction | . 157 Harry Potter and the Sorcerer&#39;s Stone: The Ill... | J.K. Rowling | 4.9 | 10052 | 22 | 2016 | Fiction | . 207 Last Week Tonight with John Oliver Presents A ... | Jill Twiss | 4.9 | 11881 | 13 | 2018 | Fiction | . 219 Little Blue Truck | Alice Schertle | 4.9 | 1884 | 0 | 2014 | Fiction | . 245 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2012 | Fiction | . 246 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2013 | Fiction | . 247 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2014 | Fiction | . 248 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2015 | Fiction | . 249 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2016 | Fiction | . 250 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2017 | Fiction | . 251 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2018 | Fiction | . 252 Oh, the Places You&#39;ll Go! | Dr. Seuss | 4.9 | 21834 | 8 | 2019 | Fiction | . 288 Rush Revere and the Brave Pilgrims: Time-Trave... | Rush Limbaugh | 4.9 | 7150 | 12 | 2013 | Fiction | . 289 Rush Revere and the First Patriots: Time-Trave... | Rush Limbaugh | 4.9 | 3836 | 12 | 2014 | Fiction | . 303 Strange Planet (Strange Planet Series) | Nathan W. Pyle | 4.9 | 9382 | 6 | 2019 | Fiction | . 420 The Legend of Zelda: Hyrule Historia | Patrick Thorpe | 4.9 | 5396 | 20 | 2013 | Fiction | . 476 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2013 | Fiction | . 477 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2014 | Fiction | . 478 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2015 | Fiction | . 479 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2016 | Fiction | . 480 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2017 | Fiction | . 481 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2018 | Fiction | . 482 The Very Hungry Caterpillar | Eric Carle | 4.9 | 19546 | 5 | 2019 | Fiction | . 486 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2016 | Fiction | . 487 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2017 | Fiction | . 488 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2018 | Fiction | . 489 The Wonderful Things You Will Be | Emily Winfield Martin | 4.9 | 8842 | 10 | 2019 | Fiction | . 545 Wrecking Ball (Diary of a Wimpy Kid Book 14) | Jeff Kinney | 4.9 | 9413 | 8 | 2019 | Fiction | . 561 Dog Man: Grime and Punishment | Dav Pilkey | 4.9 | 31045 | 6 | 2020 | Fiction | . 573 The Deep End (Diary of a Wimpy Kid Book 15) | Jeff Kinney | 4.9 | 26047 | 7 | 2020 | Fiction | . 575 I Love You to the Moon and Back | Amelia Hepworth | 4.9 | 24356 | 1 | 2020 | Fiction | . 580 Brown Bear, Brown Bear, What Do You See? | Bill Martin Jr. | 4.9 | 25321 | 5 | 2020 | Fiction | . 594 Chicka Chicka Boom Boom | Bill Martin Jr. | 4.9 | 20705 | 4 | 2020 | Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;User Rating&#39;]==df[&#39;User Rating&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 151 Hamilton: The Revolution | Lin-Manuel Miranda | 4.9 | 5867 | 54 | 2016 | Non Fiction | . 174 Humans of New York : Stories | Brandon Stanton | 4.9 | 2812 | 17 | 2015 | Non Fiction | . 187 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2011 | Non Fiction | . 188 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2012 | Non Fiction | . 189 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2013 | Non Fiction | . 190 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2014 | Non Fiction | . 191 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2015 | Non Fiction | . 192 Jesus Calling: Enjoying Peace in His Presence ... | Sarah Young | 4.9 | 19576 | 8 | 2016 | Non Fiction | . 244 Obama: An Intimate Portrait | Pete Souza | 4.9 | 3192 | 22 | 2017 | Non Fiction | . 431 The Magnolia Story | Chip Gaines | 4.9 | 7861 | 5 | 2016 | Non Fiction | . 521 Unfreedom of the Press | Mark R. Levin | 4.9 | 5956 | 11 | 2019 | Non Fiction | . 550 A Promised Land | Barack Obama | 4.9 | 83212 | 23 | 2020 | Non Fiction | . 562 The Very Hungry Caterpillar | Eric Carle | 4.9 | 35965 | 7 | 2020 | Non Fiction | . 571 The Boy, the Mole, the Fox and the Horse | Charlie Mackesy | 4.9 | 53549 | 15 | 2020 | Non Fiction | . 582 Magnolia Table, Volume 2 | Joanna Gaines | 4.9 | 16515 | 17 | 2020 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Non Fiction&#39;] df[df[&#39;Reviews&#39;]==df[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 563 Becoming | Michelle Obama | 4.8 | 99498 | 10 | 2020 | Non Fiction | . df=books[books[&#39;Genre&#39;]==&#39;Fiction&#39;] df[df[&#39;Reviews&#39;]==df[&#39;Reviews&#39;].max()] . Name Author User Rating Reviews Price Year Genre . 552 Where the Crawdads Sing | Delia Owens | 4.8 | 120727 | 9 | 2020 | Fiction | . sns.displot(x=books[&#39;Reviews&#39;], hue=books[&#39;Genre&#39;], kind=&quot;kde&quot;,fill=True) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87cea73cd0&gt; . sns.pointplot(x=&quot;Year&quot;, y=&quot;Reviews&quot;, hue=&quot;Genre&quot;, data=books, alpha=.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce6d8fd0&gt; . books[&#39;Author&#39;].value_counts() . Jeff Kinney 13 Gary Chapman 12 Suzanne Collins 12 Rick Riordan 11 American Psychological Association 10 .. Christopher Paolini 1 Jon Stewart 1 Bill Martin Jr. 1 Don Miguel Ruiz 1 Ian K. Smith M.D. 1 Name: Author, Length: 275, dtype: int64 . df=books[books[&#39;User Rating&#39;]==books[&#39;User Rating&#39;].max()] df[&#39;Author&#39;].unique() . array([&#39;Bill Martin Jr.&#39;, &#39;Dav Pilkey&#39;, &#39;Sherri Duskey Rinker&#39;, &#39;Lin-Manuel Miranda&#39;, &#39;J.K. Rowling&#39;, &#39;J. K. Rowling&#39;, &#39;Brandon Stanton&#39;, &#39;Sarah Young&#39;, &#39;Jill Twiss&#39;, &#39;Alice Schertle&#39;, &#39;Pete Souza&#39;, &#39;Dr. Seuss&#39;, &#39;Rush Limbaugh&#39;, &#39;Nathan W. Pyle&#39;, &#39;Patrick Thorpe&#39;, &#39;Chip Gaines&#39;, &#39;Eric Carle&#39;, &#39;Emily Winfield Martin&#39;, &#39;Mark R. Levin&#39;, &#39;Jeff Kinney&#39;, &#39;Barack Obama&#39;, &#39;Charlie Mackesy&#39;, &#39;Amelia Hepworth&#39;, &#39; Bill Martin Jr.&#39;, &#39;Joanna Gaines&#39;], dtype=object) . sns.stripplot(x=&quot;Genre&quot;, y=&quot;User Rating&quot;, data=books) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce3b5210&gt; . sns.heatmap(books.corr(),annot=True,cmap=&#39;magma&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f87ce2ff350&gt; . sns.clustermap(books.corr(),annot=True,cmap=&#39;magma&#39;) . &lt;seaborn.matrix.ClusterGrid at 0x7f87ce4472d0&gt; . sns.pairplot(books) . &lt;seaborn.axisgrid.PairGrid at 0x7f87cdf55590&gt; . books.head() . Name Author User Rating Reviews Price Year Genre . 0 10-Day Green Smoothie Cleanse | JJ Smith | 4.7 | 17350 | 8 | 2016 | Non Fiction | . 1 11/22/63: A Novel | Stephen King | 4.6 | 2052 | 22 | 2011 | Fiction | . 2 12 Rules for Life: An Antidote to Chaos | Jordan B. Peterson | 4.7 | 18979 | 15 | 2018 | Non Fiction | . 3 1984 (Signet Classics) | George Orwell | 4.7 | 21424 | 6 | 2017 | Fiction | . 4 5,000 Awesome Facts (About Everything!) (Natio... | National Geographic Kids | 4.8 | 7665 | 12 | 2019 | Non Fiction | . sns.lmplot(x=&#39;Price&#39;,y=&#39;Year&#39;,data=books,hue=&#39;Genre&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f87bde172d0&gt; .",
            "url": "https://sakibb019.github.io/Portfolio/2021/07/24/Amazon-Bestselling-Books-Analysis-with-Python-language.html",
            "relUrl": "/2021/07/24/Amazon-Bestselling-Books-Analysis-with-Python-language.html",
            "date": " • Jul 24, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sakibb019.github.io/Portfolio/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sakibb019.github.io/Portfolio/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sakibb019.github.io/Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sakibb019.github.io/Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}